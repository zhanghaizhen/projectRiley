{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "import re\n",
    "from HTMLParser import HTMLParser\n",
    "import datetime\n",
    "import cPickle as pickle\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Files\n",
    "all_file = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/all_withindgroup.txt'\n",
    "tech_file = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/tech_withind.txt'\n",
    "hadoop_all = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/all_hadoop.txt'\n",
    "hadoop_tech = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/tech_hadoop.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfall1 = pd.read_csv(all_file, sep=\"|\")\n",
    "dftech1 = pd.read_csv(tech_file, sep=\"|\")\n",
    "dfh = pd.read_csv(hadoop_all, sep=\"|\")\n",
    "dfht = pd.read_csv(hadoop_tech, sep=\"|\")\n",
    "\n",
    "dftech_all = pd.concat([dftech1, pd.read_csv(hadoop_tech, sep=\"|\")], axis=0)\n",
    "df_all2 = pd.concat([dfall1, pd.read_csv(hadoop_all, sep=\"|\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_vocab = str(f_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_file = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/all2.txt'\n",
    "tech_file = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/tech_all2.txt'\n",
    "\n",
    "df1 = pd.read_csv(all_file, sep=\"|\")\n",
    "df2 = pd.read_csv(tech_file, sep=\"|\")\n",
    "df = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26850 entries, 0 to 26849\n",
      "Data columns (total 24 columns):\n",
      "first_name          26850 non-null object\n",
      "full_name           26850 non-null object\n",
      "html                26850 non-null object\n",
      "industry            26850 non-null object\n",
      "location            26850 non-null object\n",
      "summary             26850 non-null object\n",
      "title               26850 non-null object\n",
      "counter             26850 non-null float64\n",
      "source              26850 non-null object\n",
      "full_name_fields    26850 non-null object\n",
      "name_fields         26850 non-null int64\n",
      "gender              26850 non-null object\n",
      "gender_type         26850 non-null object\n",
      "gender_forced       26850 non-null object\n",
      "name_counts         26850 non-null int64\n",
      "loc_fields          26850 non-null object\n",
      "state               26850 non-null object\n",
      "ind_group           26850 non-null int64\n",
      "class               26850 non-null int64\n",
      "summ_tokens         26850 non-null object\n",
      "num_tokens          26850 non-null int64\n",
      "summ_missing        26850 non-null int64\n",
      "avg_len             26850 non-null float64\n",
      "lex_diversity       26850 non-null float64\n",
      "dtypes: float64(3), int64(6), object(15)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df1[df1.industry == 'computer software']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds1 = df1[df1.title == 'Software Engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20 entries, 4622 to 26087\n",
      "Data columns (total 24 columns):\n",
      "first_name          20 non-null object\n",
      "full_name           20 non-null object\n",
      "html                20 non-null object\n",
      "industry            20 non-null object\n",
      "location            20 non-null object\n",
      "summary             20 non-null object\n",
      "title               20 non-null object\n",
      "counter             20 non-null float64\n",
      "source              20 non-null object\n",
      "full_name_fields    20 non-null object\n",
      "name_fields         20 non-null int64\n",
      "gender              20 non-null object\n",
      "gender_type         20 non-null object\n",
      "gender_forced       20 non-null object\n",
      "name_counts         20 non-null int64\n",
      "loc_fields          20 non-null object\n",
      "state               20 non-null object\n",
      "ind_group           20 non-null int64\n",
      "class               20 non-null int64\n",
      "summ_tokens         20 non-null object\n",
      "num_tokens          20 non-null int64\n",
      "summ_missing        20 non-null int64\n",
      "avg_len             20 non-null float64\n",
      "lex_diversity       20 non-null float64\n",
      "dtypes: float64(3), int64(6), object(15)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ds1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>html</th>\n",
       "      <th>industry</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>counter</th>\n",
       "      <th>source</th>\n",
       "      <th>full_name_fields</th>\n",
       "      <th>...</th>\n",
       "      <th>name_counts</th>\n",
       "      <th>loc_fields</th>\n",
       "      <th>state</th>\n",
       "      <th>ind_group</th>\n",
       "      <th>class</th>\n",
       "      <th>summ_tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>summ_missing</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>sonal</td>\n",
       "      <td>sonal aggarwal</td>\n",
       "      <td>../../data/raw/2015-12-24-caltech/sonalaggarwa...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>greater new york city area</td>\n",
       "      <td>i am a graduate student pursuing masters in c...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>caltech</td>\n",
       "      <td>['sonal', 'aggarwal']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['new', 'york']</td>\n",
       "      <td>NY</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['i', 'am', 'a', 'graduate', 'student', 'pursu...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>brian</td>\n",
       "      <td>brian ross</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/brdynamic...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>greater seattle area</td>\n",
       "      <td>i graduated with my bachelor of arts in compu...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['brian', 'ross']</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>['seattle']</td>\n",
       "      <td>WA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'graduated', 'with', 'my', 'bachelor', '...</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>5.548936</td>\n",
       "      <td>0.693617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9853</th>\n",
       "      <td>isaac</td>\n",
       "      <td>isaac myers</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/isaacmyer...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco bay area</td>\n",
       "      <td>software engineer with experience working on ...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['isaac', 'myers']</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>['san', 'francisco', 'bay']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['software', 'engineer', 'with', 'experience',...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>6.465116</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10114</th>\n",
       "      <td>janet</td>\n",
       "      <td>janet kuo</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/janetkuo....</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco bay area</td>\n",
       "      <td>5 years of work experience in software devel...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['janet', 'kuo']</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>['san', 'francisco', 'bay']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['5', 'years', 'of', 'work', 'experience', 'in...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>5.791045</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>jarrett</td>\n",
       "      <td>jarrett revels</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/jarrettre...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>washington, district of columbia</td>\n",
       "      <td>im an engineer researcher with a strong inter...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['jarrett', 'revels']</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>['washington', 'district', 'of', 'columbia']</td>\n",
       "      <td>DC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['im', 'an', 'engineer', 'researcher', 'with',...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5.692308</td>\n",
       "      <td>0.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>jeff</td>\n",
       "      <td>jeff chiu</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/codeforkj...</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>philadelphia, pennsylvania</td>\n",
       "      <td>im pretty good at making software and i even ...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['jeff', 'chiu']</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>['philadelphia', 'pennsylvania']</td>\n",
       "      <td>PA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['im', 'pretty', 'good', 'at', 'making', 'soft...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>joel</td>\n",
       "      <td>joel larsen</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/joelmaxla...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>reno, nevada</td>\n",
       "      <td>i strive to be involved in work that i am ful...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['joel', 'larsen']</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>['reno', 'nevada']</td>\n",
       "      <td>NV</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'strive', 'to', 'be', 'involved', 'in', ...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5.017544</td>\n",
       "      <td>0.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>nathaniel</td>\n",
       "      <td>nathaniel ekoniak</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/orinthe.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>seattle, washington</td>\n",
       "      <td>i am a skilled software engineer living in se...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['nathaniel', 'ekoniak']</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>['seattle', 'washington']</td>\n",
       "      <td>WA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'am', 'a', 'skilled', 'software', 'engin...</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15460</th>\n",
       "      <td>ryan</td>\n",
       "      <td>ryan allen</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/ryanaalle...</td>\n",
       "      <td>defense   space</td>\n",
       "      <td>washington d.c. metro area</td>\n",
       "      <td>specialtiesmodeling and simulation object ori...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['ryan', 'allen']</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>['washington', 'dc', 'metro']</td>\n",
       "      <td>DC</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>['specialtiesmodeling', 'and', 'simulation', '...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15911</th>\n",
       "      <td>shannon</td>\n",
       "      <td>shannon rush</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/shannonru...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>greater denver area</td>\n",
       "      <td>software engineer specializing in data scienc...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['shannon', 'rush']</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>['denver']</td>\n",
       "      <td>CO</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['software', 'engineer', 'specializing', 'in',...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16612</th>\n",
       "      <td>ted</td>\n",
       "      <td>ted ballou</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/tedballou...</td>\n",
       "      <td>computer   network security</td>\n",
       "      <td>greater chicago area</td>\n",
       "      <td>a physics major at oberlin college during sen...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['ted', 'ballou']</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>['chicago']</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'physics', 'major', 'at', 'oberlin', 'co...</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>5.754325</td>\n",
       "      <td>0.640138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>zhiyong</td>\n",
       "      <td>zhiyong joe xie</td>\n",
       "      <td>../../data/raw/2015-05-26-Washington/zhiyongxi...</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco bay area</td>\n",
       "      <td>passionate about solving the challenges of la...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>huskies</td>\n",
       "      <td>['zhiyong', 'joe', 'xie']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['san', 'francisco', 'bay']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['passionate', 'about', 'solving', 'the', 'cha...</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>5.086207</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19954</th>\n",
       "      <td>erdong</td>\n",
       "      <td>erdong fang</td>\n",
       "      <td>../raw/hadoop2015-01-09/output15525.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>arlington, virginia</td>\n",
       "      <td>looking for a full time opportunity in softwa...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['erdong', 'fang']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['arlington', 'virginia']</td>\n",
       "      <td>VA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['looking', 'for', 'a', 'full', 'time', 'oppor...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21311</th>\n",
       "      <td>josh</td>\n",
       "      <td>josh vinson</td>\n",
       "      <td>../raw/hadoop2015-01-09/output14418.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco bay area</td>\n",
       "      <td>i make things i make them work and i make the...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['josh', 'vinson']</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>['san', 'francisco', 'bay']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'make', 'things', 'i', 'make', 'them', '...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3.384615</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21776</th>\n",
       "      <td>kevin</td>\n",
       "      <td>kevin nguyen</td>\n",
       "      <td>../raw/hadoop2015-01-09/output15169.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco bay area</td>\n",
       "      <td>has general experience with multiple programm...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['kevin', 'nguyen']</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>['san', 'francisco', 'bay']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['has', 'general', 'experience', 'with', 'mult...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>5.942529</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24272</th>\n",
       "      <td>senlu</td>\n",
       "      <td>senlu tom chen</td>\n",
       "      <td>../raw/hadoop2015-01-09/output19350.html</td>\n",
       "      <td>higher education</td>\n",
       "      <td>evanston, illinois</td>\n",
       "      <td>i am a student at northwestern university stu...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['senlu', 'tom', 'chen']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['evanston', 'illinois']</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'am', 'a', 'student', 'at', 'northwester...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24844</th>\n",
       "      <td>tirso</td>\n",
       "      <td>tirso peguero</td>\n",
       "      <td>../raw/hadoop2015-01-09/output20395.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>ive always liked solving problems and being a...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['tirso', 'peguero']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['san', 'francisco', 'california']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['ive', 'always', 'liked', 'solving', 'problem...</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>4.257353</td>\n",
       "      <td>0.713235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24925</th>\n",
       "      <td>trevor</td>\n",
       "      <td>trevor adams</td>\n",
       "      <td>../raw/hadoop2015-01-09/output20420.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>san francisco bay area</td>\n",
       "      <td>software engineer with particular interest an...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['trevor', 'adams']</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>['san', 'francisco', 'bay']</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['software', 'engineer', 'with', 'particular',...</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6.121951</td>\n",
       "      <td>0.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25106</th>\n",
       "      <td>weihao</td>\n",
       "      <td>weihao ming</td>\n",
       "      <td>../raw/hadoop2015-01-09/output20767.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>greater chicago area</td>\n",
       "      <td>master student in computer science at northwe...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150109</td>\n",
       "      <td>['weihao', 'ming']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['chicago']</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['master', 'student', 'in', 'computer', 'scien...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6.346154</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26087</th>\n",
       "      <td>jinsoo</td>\n",
       "      <td>jinsoo park</td>\n",
       "      <td>../raw/hadoop2015-03-23/output2440.html</td>\n",
       "      <td>computer software</td>\n",
       "      <td>greater boston area</td>\n",
       "      <td>i am an engineer with solid background in mat...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>1</td>\n",
       "      <td>hadoop_20150323</td>\n",
       "      <td>['jinsoo', 'park']</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['boston']</td>\n",
       "      <td>MA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'am', 'an', 'engineer', 'with', 'solid',...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>6.040816</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      first_name          full_name  \\\n",
       "4622       sonal     sonal aggarwal   \n",
       "6856       brian         brian ross   \n",
       "9853       isaac        isaac myers   \n",
       "10114      janet          janet kuo   \n",
       "10160    jarrett     jarrett revels   \n",
       "10317       jeff          jeff chiu   \n",
       "10885       joel        joel larsen   \n",
       "14128  nathaniel  nathaniel ekoniak   \n",
       "15460       ryan         ryan allen   \n",
       "15911    shannon       shannon rush   \n",
       "16612        ted         ted ballou   \n",
       "17489    zhiyong    zhiyong joe xie   \n",
       "19954     erdong        erdong fang   \n",
       "21311       josh        josh vinson   \n",
       "21776      kevin       kevin nguyen   \n",
       "24272      senlu     senlu tom chen   \n",
       "24844      tirso      tirso peguero   \n",
       "24925     trevor       trevor adams   \n",
       "25106     weihao        weihao ming   \n",
       "26087     jinsoo        jinsoo park   \n",
       "\n",
       "                                                    html  \\\n",
       "4622   ../../data/raw/2015-12-24-caltech/sonalaggarwa...   \n",
       "6856   ../../data/raw/2015-05-26-Washington/brdynamic...   \n",
       "9853   ../../data/raw/2015-05-26-Washington/isaacmyer...   \n",
       "10114  ../../data/raw/2015-05-26-Washington/janetkuo....   \n",
       "10160  ../../data/raw/2015-05-26-Washington/jarrettre...   \n",
       "10317  ../../data/raw/2015-05-26-Washington/codeforkj...   \n",
       "10885  ../../data/raw/2015-05-26-Washington/joelmaxla...   \n",
       "14128  ../../data/raw/2015-05-26-Washington/orinthe.html   \n",
       "15460  ../../data/raw/2015-05-26-Washington/ryanaalle...   \n",
       "15911  ../../data/raw/2015-05-26-Washington/shannonru...   \n",
       "16612  ../../data/raw/2015-05-26-Washington/tedballou...   \n",
       "17489  ../../data/raw/2015-05-26-Washington/zhiyongxi...   \n",
       "19954           ../raw/hadoop2015-01-09/output15525.html   \n",
       "21311           ../raw/hadoop2015-01-09/output14418.html   \n",
       "21776           ../raw/hadoop2015-01-09/output15169.html   \n",
       "24272           ../raw/hadoop2015-01-09/output19350.html   \n",
       "24844           ../raw/hadoop2015-01-09/output20395.html   \n",
       "24925           ../raw/hadoop2015-01-09/output20420.html   \n",
       "25106           ../raw/hadoop2015-01-09/output20767.html   \n",
       "26087            ../raw/hadoop2015-03-23/output2440.html   \n",
       "\n",
       "                                  industry                          location  \\\n",
       "4622                     computer software        greater new york city area   \n",
       "6856                     computer software              greater seattle area   \n",
       "9853                     computer software            san francisco bay area   \n",
       "10114                    computer software            san francisco bay area   \n",
       "10160                    computer software  washington, district of columbia   \n",
       "10317  information technology and services        philadelphia, pennsylvania   \n",
       "10885                    computer software                      reno, nevada   \n",
       "14128                    computer software               seattle, washington   \n",
       "15460                      defense   space        washington d.c. metro area   \n",
       "15911                    computer software               greater denver area   \n",
       "16612          computer   network security              greater chicago area   \n",
       "17489                    computer software            san francisco bay area   \n",
       "19954                    computer software               arlington, virginia   \n",
       "21311                    computer software            san francisco bay area   \n",
       "21776                    computer software            san francisco bay area   \n",
       "24272                     higher education                evanston, illinois   \n",
       "24844                    computer software         san francisco, california   \n",
       "24925                    computer software            san francisco bay area   \n",
       "25106                    computer software              greater chicago area   \n",
       "26087                    computer software               greater boston area   \n",
       "\n",
       "                                                 summary              title  \\\n",
       "4622    i am a graduate student pursuing masters in c...  Software Engineer   \n",
       "6856    i graduated with my bachelor of arts in compu...  Software Engineer   \n",
       "9853    software engineer with experience working on ...  Software Engineer   \n",
       "10114    5 years of work experience in software devel...  Software Engineer   \n",
       "10160   im an engineer researcher with a strong inter...  Software Engineer   \n",
       "10317   im pretty good at making software and i even ...  Software Engineer   \n",
       "10885   i strive to be involved in work that i am ful...  Software Engineer   \n",
       "14128   i am a skilled software engineer living in se...  Software Engineer   \n",
       "15460   specialtiesmodeling and simulation object ori...  Software Engineer   \n",
       "15911   software engineer specializing in data scienc...  Software Engineer   \n",
       "16612   a physics major at oberlin college during sen...  Software Engineer   \n",
       "17489   passionate about solving the challenges of la...  Software Engineer   \n",
       "19954   looking for a full time opportunity in softwa...  Software Engineer   \n",
       "21311   i make things i make them work and i make the...  Software Engineer   \n",
       "21776   has general experience with multiple programm...  Software Engineer   \n",
       "24272   i am a student at northwestern university stu...  Software Engineer   \n",
       "24844   ive always liked solving problems and being a...  Software Engineer   \n",
       "24925   software engineer with particular interest an...  Software Engineer   \n",
       "25106   master student in computer science at northwe...  Software Engineer   \n",
       "26087   i am an engineer with solid background in mat...  Software Engineer   \n",
       "\n",
       "       counter           source           full_name_fields      ...       \\\n",
       "4622         1          caltech      ['sonal', 'aggarwal']      ...        \n",
       "6856         1          huskies          ['brian', 'ross']      ...        \n",
       "9853         1          huskies         ['isaac', 'myers']      ...        \n",
       "10114        1          huskies           ['janet', 'kuo']      ...        \n",
       "10160        1          huskies      ['jarrett', 'revels']      ...        \n",
       "10317        1          huskies           ['jeff', 'chiu']      ...        \n",
       "10885        1          huskies         ['joel', 'larsen']      ...        \n",
       "14128        1          huskies   ['nathaniel', 'ekoniak']      ...        \n",
       "15460        1          huskies          ['ryan', 'allen']      ...        \n",
       "15911        1          huskies        ['shannon', 'rush']      ...        \n",
       "16612        1          huskies          ['ted', 'ballou']      ...        \n",
       "17489        1          huskies  ['zhiyong', 'joe', 'xie']      ...        \n",
       "19954        1  hadoop_20150109         ['erdong', 'fang']      ...        \n",
       "21311        1  hadoop_20150109         ['josh', 'vinson']      ...        \n",
       "21776        1  hadoop_20150109        ['kevin', 'nguyen']      ...        \n",
       "24272        1  hadoop_20150109   ['senlu', 'tom', 'chen']      ...        \n",
       "24844        1  hadoop_20150109       ['tirso', 'peguero']      ...        \n",
       "24925        1  hadoop_20150109        ['trevor', 'adams']      ...        \n",
       "25106        1  hadoop_20150109         ['weihao', 'ming']      ...        \n",
       "26087        1  hadoop_20150323         ['jinsoo', 'park']      ...        \n",
       "\n",
       "       name_counts                                    loc_fields state  \\\n",
       "4622             1                               ['new', 'york']    NY   \n",
       "6856           113                                   ['seattle']    WA   \n",
       "9853             7                   ['san', 'francisco', 'bay']    CA   \n",
       "10114           23                   ['san', 'francisco', 'bay']    CA   \n",
       "10160            3  ['washington', 'district', 'of', 'columbia']    DC   \n",
       "10317          100              ['philadelphia', 'pennsylvania']    PA   \n",
       "10885           20                            ['reno', 'nevada']    NV   \n",
       "14128            6                     ['seattle', 'washington']    WA   \n",
       "15460          102                 ['washington', 'dc', 'metro']    DC   \n",
       "15911           30                                    ['denver']    CO   \n",
       "16612            9                                   ['chicago']    IL   \n",
       "17489            1                   ['san', 'francisco', 'bay']    CA   \n",
       "19954            1                     ['arlington', 'virginia']    VA   \n",
       "21311           24                   ['san', 'francisco', 'bay']    CA   \n",
       "21776           60                   ['san', 'francisco', 'bay']    CA   \n",
       "24272            1                      ['evanston', 'illinois']    IL   \n",
       "24844            1            ['san', 'francisco', 'california']    CA   \n",
       "24925           10                   ['san', 'francisco', 'bay']    CA   \n",
       "25106            1                                   ['chicago']    IL   \n",
       "26087            1                                    ['boston']    MA   \n",
       "\n",
       "      ind_group  class                                        summ_tokens  \\\n",
       "4622          2      0  ['i', 'am', 'a', 'graduate', 'student', 'pursu...   \n",
       "6856          2      1  ['i', 'graduated', 'with', 'my', 'bachelor', '...   \n",
       "9853          2      1  ['software', 'engineer', 'with', 'experience',...   \n",
       "10114         2      0  ['5', 'years', 'of', 'work', 'experience', 'in...   \n",
       "10160         2      1  ['im', 'an', 'engineer', 'researcher', 'with',...   \n",
       "10317         2      1  ['im', 'pretty', 'good', 'at', 'making', 'soft...   \n",
       "10885         2      1  ['i', 'strive', 'to', 'be', 'involved', 'in', ...   \n",
       "14128         2      1  ['i', 'am', 'a', 'skilled', 'software', 'engin...   \n",
       "15460         3      1  ['specialtiesmodeling', 'and', 'simulation', '...   \n",
       "15911         2      0  ['software', 'engineer', 'specializing', 'in',...   \n",
       "16612         3      1  ['a', 'physics', 'major', 'at', 'oberlin', 'co...   \n",
       "17489         2      1  ['passionate', 'about', 'solving', 'the', 'cha...   \n",
       "19954         2      1  ['looking', 'for', 'a', 'full', 'time', 'oppor...   \n",
       "21311         2      1  ['i', 'make', 'things', 'i', 'make', 'them', '...   \n",
       "21776         2      1  ['has', 'general', 'experience', 'with', 'mult...   \n",
       "24272         1      1  ['i', 'am', 'a', 'student', 'at', 'northwester...   \n",
       "24844         2      1  ['ive', 'always', 'liked', 'solving', 'problem...   \n",
       "24925         2      1  ['software', 'engineer', 'with', 'particular',...   \n",
       "25106         2      1  ['master', 'student', 'in', 'computer', 'scien...   \n",
       "26087         2      1  ['i', 'am', 'an', 'engineer', 'with', 'solid',...   \n",
       "\n",
       "      num_tokens  summ_missing   avg_len lex_diversity  \n",
       "4622          24             0  5.875000      0.958333  \n",
       "6856         235             0  5.548936      0.693617  \n",
       "9853          43             0  6.465116      0.767442  \n",
       "10114         67             0  5.791045      0.626866  \n",
       "10160         39             0  5.692308      0.948718  \n",
       "10317         16             0  3.812500      1.000000  \n",
       "10885         57             0  5.017544      0.859649  \n",
       "14128         56             0  5.214286      0.750000  \n",
       "15460          9             0  7.777778      0.888889  \n",
       "15911         12             0  6.333333      1.000000  \n",
       "16612        289             0  5.754325      0.640138  \n",
       "17489         58             0  5.086207      0.862069  \n",
       "19954         10             0  6.100000      1.000000  \n",
       "21311         13             0  3.384615      0.615385  \n",
       "21776         87             0  5.942529      0.666667  \n",
       "24272         20             0  4.950000      0.950000  \n",
       "24844        136             0  4.257353      0.713235  \n",
       "24925         41             0  6.121951      0.756098  \n",
       "25106         26             0  6.346154      0.884615  \n",
       "26087         49             0  6.040816      0.857143  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1456 entries, 17 to 26825\n",
      "Data columns (total 24 columns):\n",
      "first_name          1456 non-null object\n",
      "full_name           1456 non-null object\n",
      "html                1456 non-null object\n",
      "industry            1456 non-null object\n",
      "location            1456 non-null object\n",
      "summary             1456 non-null object\n",
      "title               1456 non-null object\n",
      "counter             1456 non-null float64\n",
      "source              1456 non-null object\n",
      "full_name_fields    1456 non-null object\n",
      "name_fields         1456 non-null int64\n",
      "gender              1456 non-null object\n",
      "gender_type         1456 non-null object\n",
      "gender_forced       1456 non-null object\n",
      "name_counts         1456 non-null int64\n",
      "loc_fields          1456 non-null object\n",
      "state               1456 non-null object\n",
      "ind_group           1456 non-null int64\n",
      "class               1456 non-null int64\n",
      "summ_tokens         1456 non-null object\n",
      "num_tokens          1456 non-null int64\n",
      "summ_missing        1456 non-null int64\n",
      "avg_len             1456 non-null float64\n",
      "lex_diversity       1456 non-null float64\n",
      "dtypes: float64(3), int64(6), object(15)\n",
      "memory usage: 284.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def missing(df):\n",
    "    if df.summary == 'missing' or df.num_tokens == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "    \n",
    "def lenx(mystr):\n",
    "    return len(mystr.split())\n",
    "\n",
    "\n",
    "def avgchrs(mytokens):\n",
    "    tw = len(mytokens)    \n",
    "    num_chars = 0\n",
    "    for word in mytokens:\n",
    "        num_chars += len(word)        \n",
    "    return num_chars/tw\n",
    "\n",
    "\n",
    "def remove_digits(mystr):\n",
    "    '''\n",
    "    INPUT: list of tokens \n",
    "    OUTPUT: list of tokens with digits removed\n",
    "    '''\n",
    "    result = []\n",
    "    mystopwords = ['management', 'development', 'experience', 'including', 'well', 'years']\n",
    "    mystopwords = set(stopwords)\n",
    "    for word in mystr:\n",
    "        if not word.isdigit():\n",
    "            if word not in mystopwords:\n",
    "                result.append(word)\n",
    "        return result\n",
    "\n",
    "            \n",
    "    #return [word for word in mystr if not word.isdigit() and not in ['management', 'development', 'experience', 'including', 'well', 'years']]\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    row = remove_digits(tokens)\n",
    "    stems = stem_tokens(row, stemmer)\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_no_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    row = remove_digits(tokens)\n",
    "    stems = stem_tokens(row, stemmer)\n",
    "    return tokens \n",
    "\n",
    "def preprocess_df(df):\n",
    "    # Feature Engineering before running the prediction code\n",
    "    df['class'] = np.ones(len(df))\n",
    "    df['class'] = df['gender_forced'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "\n",
    "    df['summ_tokens'] = df['summary'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    df['num_tokens'] = df['summ_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "    # Add feature for missing summary\n",
    "    df['summ_missing'] = df.apply(missing, axis = 1)\n",
    "\n",
    "    # Only include rows with summaries\n",
    "    df = df[df['summ_missing'] == 0]\n",
    "\n",
    "    # Some Nan rows refuse to go without this\n",
    "    df = df[pd.notnull(df['summary'])]\n",
    "\n",
    "    print (\"Length of DF after removing rows with missing Summaries:\\n\")\n",
    "    print (len(df))\n",
    "\n",
    "    df['avg_len'] = df['summ_tokens'].apply(lambda x: avgchrs(x))\n",
    "\n",
    "    # lexical diversity = number of unique tokens / total number of tokens\n",
    "    df['lex_diversity'] = df['summ_tokens'].apply(lambda x: len(set(x))/len(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the top 20 words and weights for each topic\n",
    "def print_top_weights(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        top_weights = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        #print (top_weights)\n",
    "        print (\" \".join([\"{0}, {1}\".format(feature_names[x], topic[x]) for x in top_weights]))\n",
    "    print()\n",
    "    \n",
    "\n",
    "# Print the most probable topic for each document/profile\n",
    "def profiles_by_topic(W):\n",
    "    top_idx = np.zeros([W.shape[0],1], dtype=int)\n",
    "    for row_idx, row in enumerate(W):\n",
    "        topic_idx = row.argsort()[-1]  \n",
    "        top_idx[row_idx] = topic_idx\n",
    "    topics, counts = np.unique(top_idx, return_counts=True)\n",
    "    print (np.asarray((topics, counts)).T)\n",
    "    return top_idx\n",
    "\n",
    "           \n",
    "def run_topic_model_tfidf(X, stopwords):\n",
    "    print (\"Bag of Words, Tfidf\\n\")\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(analyzer = 'word', tokenizer = tokenize_no_stem, stop_words = stopwords, max_features = 5000)\n",
    "    word_frequencies = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Numpy arrays are easy to work with, so convert the result to an \n",
    "    # array\n",
    "    word_frequencies = word_frequencies.toarray()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    # NMF Model to determine topics\n",
    "    nmf_model = NMF(n_components=4, init='random', random_state=0)\n",
    "    W = nmf_model.fit_transform(word_frequencies)\n",
    "    # H: Topics * Words\n",
    "    H = nmf_model.components_\n",
    "    print (H.shape, W.shape)\n",
    "    \n",
    "    n_top_words = 20\n",
    "    # Print weights and topics for the top 20 topics\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        top_weights = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        print (\" \".join([\"{0}\".format(feature_names[x]) for x in top_weights]))\n",
    "    print()\n",
    "    \n",
    "    # Highest Weighted Topic for each profile\n",
    "    print (\"Number of profiles by topic\\n\")\n",
    "    top_idx = profiles_by_topic(W) \n",
    "    \n",
    "    return nmf_model, W, top_idx\n",
    "\n",
    "\n",
    "#tokenize: function that is stemming using SnowballStemmer\n",
    "#stopwords: custom stop words\n",
    "def run_topic_model_countv(X, stopwords):\n",
    "    print (\"Bag of words, Count Vectorizer...\\n\")\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = tokenize_no_stem,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = stopwords,   \\\n",
    "                                 max_df = 0.7, \\\n",
    "                                 min_df = 5, \\\n",
    "                                 max_features = 5000) \n",
    "\n",
    "\n",
    "    # fit_transform() does two functions: First, it fits the model\n",
    "    # and learns the vocabulary; second, it transforms our training data\n",
    "    # into feature vectors. The input to fit_transform should be a list of \n",
    "    # strings.\n",
    "    word_frequencies = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Numpy arrays are easy to work with, so convert the result to an \n",
    "    # array\n",
    "    word_frequencies = word_frequencies.toarray()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    # NMF Model to determine topics\n",
    "    nmf_model = NMF(n_components=4, init='random', random_state=0)\n",
    "    W = nmf_model.fit_transform(word_frequencies)\n",
    "    # H: Topics * Words\n",
    "    H = nmf_model.components_\n",
    "    print (H.shape, W.shape)\n",
    "    \n",
    "    n_top_words = 20\n",
    "    # Print weights and topics for the top 20 topics\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        top_weights = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        #print (\" \".join([\"{0}\".format(feature_names[x]) for x in top_weights]))\n",
    "        print (\" \".join([\"{0}, {1}\".format(feature_names[x], topic[x]) for x in top_weights]))\n",
    "    print()\n",
    "    \n",
    "    print (\"Number of profiles by Topic\\n\")\n",
    "    top_idx = profiles_by_topic(W)\n",
    "    \n",
    "    #print (\"Example Profiles by Topic\\n\")\n",
    "    \n",
    "    return nmf_model, W, top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_models_by_df(df):\n",
    "    df = preprocess_df(df)\n",
    "    females = df[df['gender'] == 'female']\n",
    "    males = df[df['gender'] == 'male']\n",
    "\n",
    "    X = df['summary']\n",
    "    y = np.array(df['class'])\n",
    "    print (\"Topics for ALL profiles: TFIDF\\n\")\n",
    "    nmf_model, W, top_idx = run_topic_model_tfidf(X, stopwords)\n",
    "    \n",
    "    print (\"Topics for ALL profiles: Count Vectorizer\\n\")\n",
    "    nmf_model, W, top_idx = run_topic_model_countv(X, stopwords)\n",
    "\n",
    "    X = females['summary']\n",
    "    y = np.array(females['class'])\n",
    "    print (\"Topics for FEMALE profiles: TFIDF\\n\")\n",
    "    nmf_model, W, top_idx = run_topic_model_tfidf(X, stopwords)\n",
    "    print (\"Topics for FEMALE profiles: Count Vectorizer\\n\")\n",
    "    nmf_model, W, top_idx = run_topic_model_countv(X, stopwords)\n",
    "\n",
    "    X = males['summary']\n",
    "    y = np.array(males['class'])\n",
    "    print (\"Topics for MALE profiles: TFIDF\\n\")\n",
    "    nmf_model, W, top_idx = run_topic_model_tfidf(X, stopwords)\n",
    "    print (\"Topics for MALE profiles: Count Vectorizer\\n\")\n",
    "    nmf_model, W, top_idx = run_topic_model_countv(X, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DF after removing rows with missing Summaries:\n",
      "\n",
      "26850\n",
      "Length of DF after removing rows with missing Summaries:\n",
      "\n",
      "26850\n",
      "Topics for ALL profiles: TFIDF\n",
      "\n",
      "Bag of Words, Tfidf\n",
      "\n",
      "(4, 5000) (26850, 4)\n",
      "Topic #0:\n",
      "production collaborate honest ones supervising 1000 perspective los forwardthinking budget dc timelines applicable stores adventures lake returned doe curriculum parts\n",
      "Topic #1:\n",
      "mi awesome wholesale much fan 2007 pennsylvania israel consider cell xhtml values predictive partnership latin expenses 2011 ceo psychology hebrew\n",
      "Topic #2:\n",
      "driven display audience reproductive ownership catalog missions repair thinker engagement lgbt grants group qualifications general position governments spread blogger oneonone\n",
      "Topic #3:\n",
      "nontechnical woman employee cook scheduling steve catholic vermont creator iraq recruiters distributed officers biophysics network inspirational evangelist wellversed brown invitations\n",
      "\n",
      "Number of profiles by topic\n",
      "\n",
      "[[   0 5720]\n",
      " [   1 5054]\n",
      " [   2 7762]\n",
      " [   3 8314]]\n",
      "Topics for ALL profiles: Count Vectorizer\n",
      "\n",
      "Bag of words, Count Vectorizer...\n",
      "\n",
      "(4, 5000) (26850, 4)\n",
      "Topic #0:\n",
      "management, 65.4630967742 research, 54.7746234095 design, 48.1734427845 education, 37.6653596683 experience, 35.0433783507 years, 35.024617188 development, 32.9292295904 university, 28.3840827749 business, 27.5846223 team, 26.0789832545 training, 25.9186890727 social, 24.9925725306 sales, 23.4412273589 product, 23.212369117 online, 22.563062869 planning, 22.1401795047 music, 22.136226489 software, 21.9912568368 engineering, 21.232868384 community, 21.0435307536\n",
      "Topic #1:\n",
      "development, 58.9505218706 management, 57.0870542002 experience, 47.9425846457 analysis, 40.0375694382 university, 38.3815383178 data, 37.9731430566 research, 37.5123901108 technology, 33.3582041197 including, 31.1275825654 projects, 29.2867379595 science, 27.5839679271 also, 26.9549864045 information, 26.8996389761 international, 24.2826684526 new, 22.7316610219 art, 20.6799170461 worked, 20.523285843 national, 20.4263336044 years, 19.9986728994 systems, 19.4627979415\n",
      "Topic #2:\n",
      "business, 56.2130797498 development, 56.1381958209 university, 44.2620727472 design, 43.6388085231 management, 40.0378830152 media, 37.1124591018 public, 36.7386606737 international, 30.3403396027 project, 29.0930449559 years, 27.3499934016 law, 25.7928978109 new, 24.8670102075 school, 24.6275368548 industry, 22.5499848344 engineering, 22.3302553589 policy, 22.3131105417 health, 22.1010081642 leadership, 20.4233967012 career, 20.2667887422 also, 19.8937021969\n",
      "Topic #3:\n",
      "experience, 80.277992361 marketing, 67.0251013741 work, 65.2449454402 management, 61.9855990004 business, 61.9449911839 skills, 57.7538224939 leadership, 35.4637838602 new, 32.3905279973 professional, 30.8625137725 project, 30.4337629075 years, 29.6713860187 working, 27.8311351574 planning, 27.457270104 well, 26.5739287081 strategic, 25.5176415766 communication, 25.0557420787 strong, 24.9508041996 development, 22.2191769246 program, 22.0668272215 social, 21.4954037266\n",
      "\n",
      "Number of profiles by Topic\n",
      "\n",
      "[[   0 5573]\n",
      " [   1 7305]\n",
      " [   2 5461]\n",
      " [   3 8511]]\n",
      "Topics for FEMALE profiles: TFIDF\n",
      "\n",
      "Bag of Words, Tfidf\n",
      "\n",
      "(4, 5000) (8855, 4)\n",
      "Topic #0:\n",
      "advocacy guy believes sponsored pittsburgh angel soft del software emotions large learners mix atlanta ready robert programme accountability core penetration\n",
      "Topic #1:\n",
      "codes associated single publish multiplatform hours informal costume already ethics iv trend contributed discussions investigator web arabic intense signal remote\n",
      "Topic #2:\n",
      "acted name phases fellowship gaining specialities auditing division keeping ca africa chartered chromatography uk get equality efficiencies fda compete passed\n",
      "Topic #3:\n",
      "summary combination fellowships guatemala clinics expression witness studio g without enhance ajax keen convention colleagues n identifying context exhibits preschool\n",
      "\n",
      "Number of profiles by topic\n",
      "\n",
      "[[   0 1700]\n",
      " [   1 2658]\n",
      " [   2 2617]\n",
      " [   3 1880]]\n",
      "Topics for FEMALE profiles: Count Vectorizer\n",
      "\n",
      "Bag of words, Count Vectorizer...\n",
      "\n",
      "(4, 5000) (8855, 4)\n",
      "Topic #0:\n",
      "management, 45.4191545938 experience, 39.8144730512 development, 33.7690279716 research, 32.5863679869 years, 26.3042280686 marketing, 25.1648045214 business, 25.0427107007 skills, 23.5536229686 university, 22.9088710378 work, 22.2581844307 health, 20.5602790833 professional, 18.9511802085 design, 17.6629964052 international, 17.6269811438 working, 17.4669675394 new, 17.1993335928 program, 17.1289263205 public, 16.8602698815 education, 16.7095923871 also, 15.630530509\n",
      "Topic #1:\n",
      "management, 37.635370927 experience, 32.0726278558 business, 26.6438729091 development, 26.6324377151 design, 22.9759003901 work, 22.8411643011 skills, 20.6611154483 marketing, 20.6404887271 years, 18.7010973581 university, 17.4721431996 professional, 16.6499909095 project, 16.5020825246 research, 16.4381952945 new, 16.2092934927 media, 13.0761680392 social, 12.6384045796 working, 12.5685106876 writing, 12.3754570164 team, 12.1843113498 also, 11.7809177235\n",
      "Topic #2:\n",
      "management, 32.2101402392 experience, 27.2666173644 business, 26.5788524336 development, 24.0904821213 university, 20.1946267637 social, 17.6733322056 work, 16.4712164743 research, 16.3654073232 years, 15.3831703408 marketing, 14.7762705988 new, 14.6685409228 project, 13.8555204114 also, 13.3777984146 specialties, 13.2608913683 public, 12.6999860457 health, 12.5474651449 media, 12.3175566533 design, 11.8751010397 planning, 11.3597081314 community, 11.312573325\n",
      "Topic #3:\n",
      "management, 28.5236409103 experience, 26.759649532 development, 22.6261617905 university, 20.5063612321 research, 19.8171656652 work, 17.3853407797 business, 16.4670283422 new, 16.1075090536 marketing, 15.2847805437 years, 14.6037923731 project, 14.4469524296 media, 14.2411462243 also, 13.8489929814 education, 13.6120095414 skills, 13.5741133813 health, 12.7478383143 social, 11.91498289 design, 11.7246154798 program, 11.4763781184 professional, 11.0096183807\n",
      "\n",
      "Number of profiles by Topic\n",
      "\n",
      "[[   0 3506]\n",
      " [   1 2129]\n",
      " [   2 1795]\n",
      " [   3 1425]]\n",
      "Topics for MALE profiles: TFIDF\n",
      "\n",
      "Bag of Words, Tfidf\n",
      "\n",
      "(4, 5000) (17995, 4)\n",
      "Topic #0:\n",
      "engines ranging plans therapies standard concerns note covering diabetes rewarding detail america personable networking seo dependable surgical familiarity glass utility\n",
      "Topic #1:\n",
      "interact cad auditor thinking someone physician usually personal photographs aim al analyze arcgis schedules accenture highlights realtor independently short ensembles\n",
      "Topic #2:\n",
      "reference spoken sensing cost multimedia ability 12 around mission identified responsible xp forestry civilian current congress publications comes 1992 inform\n",
      "Topic #3:\n",
      "equipment thanks narrative existing sensors boy jeff considerable algebra translating circumstances agile method fashion rd sectors rep postgresql merchandising charles\n",
      "\n",
      "Number of profiles by topic\n",
      "\n",
      "[[   0 4320]\n",
      " [   1 4964]\n",
      " [   2 3996]\n",
      " [   3 4715]]\n",
      "Topics for MALE profiles: Count Vectorizer\n",
      "\n",
      "Bag of words, Count Vectorizer...\n",
      "\n",
      "(4, 5000) (17995, 4)\n",
      "Topic #0:\n",
      "management, 66.5603658995 experience, 48.983338928 development, 38.6313448798 business, 32.5846060406 research, 30.4971535866 university, 24.4095868428 project, 23.765198974 marketing, 22.4342644694 social, 21.6954498566 skills, 21.4723361266 years, 20.9705825155 data, 20.5703358729 design, 19.8316914691 new, 19.5091435123 work, 17.8189199672 analysis, 16.7348191859 leadership, 16.4728966752 professional, 15.3839344046 media, 15.3642730632 specialties, 15.145519998\n",
      "Topic #1:\n",
      "management, 50.2824157694 experience, 34.9095263874 business, 31.2093897269 university, 31.054777799 years, 28.8575145576 development, 26.9984017937 design, 22.3156350639 marketing, 20.4469575778 work, 20.4283672144 research, 19.8869392702 international, 19.7379426454 public, 19.5972220981 education, 19.1409633651 skills, 18.9541175701 sales, 18.8506347545 program, 18.544401077 new, 17.7629327029 also, 17.7319365595 leadership, 17.1281085065 project, 16.8358217428\n",
      "Topic #2:\n",
      "business, 39.0282377688 development, 37.2808379235 experience, 24.889567702 management, 21.4729387082 work, 20.8660493828 design, 16.7324218421 university, 16.3959136115 also, 15.7460630846 years, 15.4599340274 new, 15.2065026419 including, 14.5609169341 technology, 14.0742588498 planning, 12.7960842194 research, 12.540230323 working, 12.4979161441 specialties, 11.3339142421 marketing, 11.0083528101 music, 10.4004561335 science, 10.3393645768 software, 10.0247704669\n",
      "Topic #3:\n",
      "management, 30.2080954624 experience, 29.8469527066 development, 28.6426519853 business, 23.9262275247 research, 21.0559497329 design, 20.1689024683 years, 18.1449613965 technology, 17.7788793453 university, 17.296503031 marketing, 16.8385752808 systems, 15.2284338127 analysis, 15.0210473235 professional, 13.2408177355 planning, 12.9135309701 project, 12.894663652 work, 12.8086264217 engineering, 12.5136322214 including, 12.0070600332 new, 11.8818602816 career, 11.7486832713\n",
      "\n",
      "Number of profiles by Topic\n",
      "\n",
      "[[   0 5562]\n",
      " [   1 5867]\n",
      " [   2 3511]\n",
      " [   3 3055]]\n"
     ]
    }
   ],
   "source": [
    "df= preprocess_df(df)\n",
    "topic_models_by_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = preprocess_df(df)\n",
    "females = df[df['gender'] == 'female']\n",
    "males = df[df['gender'] == 'male']\n",
    "\n",
    "X = df['summary']\n",
    "y = np.array(df['class'])\n",
    "\n",
    "print (\"Topics for ALL profiles: Count Vectorizer\\n\")\n",
    "nmf_model, W, top_idx = run_topic_model_countv(X, stopwords)\n",
    "\n",
    "X = females['summary']\n",
    "y = np.array(females['class'])\n",
    "\n",
    "print (\"Topics for FEMALE profiles: Count Vectorizer\\n\")\n",
    "nmf_model, W, top_idx = run_topic_model_countv(X, stopwords)\n",
    "\n",
    "X = males['summary']\n",
    "y = np.array(males['class'])\n",
    "\n",
    "print (\"Topics for MALE profiles: Count Vectorizer\\n\")\n",
    "nmf_model, W, top_idx = run_topic_model_countv(X, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
