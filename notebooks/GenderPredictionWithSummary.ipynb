{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import re\n",
    "from HTMLParser import HTMLParser\n",
    "import datetime\n",
    "import cPickle as pickle\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Files\n",
    "all_file = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/all_withindgroup.txt'\n",
    "tech_file = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/tech_withind.txt'\n",
    "hadoop_all = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/all_hadoop.txt'\n",
    "hadoop_tech = '/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/tech_hadoop.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfall1 = pd.read_csv(all_file, sep=\"|\")\n",
    "dftech1 = pd.read_csv(tech_file, sep=\"|\")\n",
    "dfh = pd.read_csv(hadoop_all, sep=\"|\")\n",
    "dfht = pd.read_csv(hadoop_tech, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dftech1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-40ff4ef4bb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdftech_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdftech1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhadoop_tech\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dftech1' is not defined"
     ]
    }
   ],
   "source": [
    "dftech_all = pd.concat([dftech1, pd.read_csv(hadoop_tech, sep=\"|\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfall1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-af0c787ce673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_all2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfall1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhadoop_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfall1' is not defined"
     ]
    }
   ],
   "source": [
    "df_all2 = pd.concat([dfall1, pd.read_csv(hadoop_all, sep=\"|\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all2.to_csv('/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/all2.txt', sep=\"|\", index=False)\n",
    "dftech_all.to_csv('/Users/lekha/galvanize/capstone/projectRiley/data/withindgroup/tech_all2.txt', sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_all2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['first_name'] = df['first_name'].apply(lambda x:'andrew' if x=='anew' else x)\n",
    "df.loc[df.first_name.isin(['andrew']), 'gender'] = 'male'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling - Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def missing(df):\n",
    "    if df.summary == 'missing' or df.num_tokens == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "    \n",
    "def lenx(mystr):\n",
    "    return len(mystr.split())\n",
    "\n",
    "\n",
    "def avgchrs(mytokens):\n",
    "    tw = len(mytokens)    \n",
    "    num_chars = 0\n",
    "    for word in mytokens:\n",
    "        num_chars += len(word)        \n",
    "    return num_chars/tw\n",
    "\n",
    "\n",
    "def remove_digits(mystr):\n",
    "    '''\n",
    "    INPUT: list of tokens \n",
    "    OUTPUT: list of tokens with digits removed\n",
    "    '''\n",
    "    return [word for word in mystr if not word.isdigit()]\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    row = remove_digits(tokens)\n",
    "    stems = stem_tokens(row, stemmer)\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_no_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    row = remove_digits(tokens)\n",
    "    stems = stem_tokens(row, stemmer)\n",
    "    return tokens \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # Feature Engineering before running the prediction code\n",
    "    df['class'] = np.ones(len(df))\n",
    "    df['class'] = df['gender_forced'].apply(lambda x: 0 if x == 'female' else 1)\n",
    "\n",
    "    df['summ_tokens'] = df['summary'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "    df['num_tokens'] = df['summ_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "    # Add feature for missing summary\n",
    "    df['summ_missing'] = df.apply(missing, axis = 1)\n",
    "\n",
    "    # Only include rows with summaries\n",
    "    df = df[df['summ_missing'] == 0]\n",
    "\n",
    "    # Some Nan rows refuse to go without this\n",
    "    df = df[pd.notnull(df['summary'])]\n",
    "\n",
    "    print (\"Length of DF after removing rows with missing Summaries:\\n\")\n",
    "    print (len(df))\n",
    "\n",
    "    df['avg_len'] = df['summ_tokens'].apply(lambda x: avgchrs(x))\n",
    "\n",
    "    # lexical diversity = number of unique tokens / total number of tokens\n",
    "    df['lex_diversity'] = df['summ_tokens'].apply(lambda x: len(set(x))/len(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rf_predict(df):\n",
    "# Train-test split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['summary'], df['class'], test_size=0.3, random_state=0)\n",
    "    vectorizer = CountVectorizer(analyzer = 'word', tokenizer = tokenize, ngram_range=(1,4), stop_words = stopwords, max_df = 0.7, min_df = 5, max_features = 5000)\n",
    "    train_fit = vectorizer.fit_transform(X_train)\n",
    "    train_fit = train_fit.toarray()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    print (\"Training the random forest...\")\n",
    "\n",
    "    # Initialize a Random Forest classifier with 100 trees\n",
    "    forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "    # Fit the forest to the training set, using the bag of words as \n",
    "    # features and the sentiment labels as the response variable\n",
    "    #\n",
    "    # This may take a few minutes to run\n",
    "    forest = forest.fit(train_fit, y_train)\n",
    "\n",
    "    # Testing\n",
    "\n",
    "    # Get a bag of words for the test set, and convert to a numpy array\n",
    "    #test_data_features = vectorizer.transform(X_test)\n",
    "    test_features = vectorizer.transform(X_test)\n",
    "    test_features = test_features.toarray()\n",
    "\n",
    "    # Use the random forest to make sentiment label predictions\n",
    "    yhat = forest.predict(test_features)\n",
    "    probX = forest.predict_proba(test_features)\n",
    "\n",
    "    print (\"Precision Score: {0}\".format(precision_score(y_test, yhat)))\n",
    "    print (\"Recall Score: {0}\".format(recall_score(y_test, yhat)))\n",
    "    print (\"AUC Score: {0}\".format(roc_auc_score(y_test, yhat)))\n",
    "    print (\"Model Score:{0}\".format(forest.score(test_features, y_test)))\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probX[:,1])    \n",
    "    \n",
    "    # Most important features\n",
    "    num = 50\n",
    "    imp = forest.feature_importances_\n",
    "    feature_names = np.array(feature_names)\n",
    "    features = feature_names[np.argsort(imp)[-num:]]\n",
    "    weights = imp[np.argsort(imp)[-num:]]\n",
    "    feats_with_vals = zip(features, weights)\n",
    "    print (\"Top 50 Features\\n\")\n",
    "    for x in feats_with_vals:\n",
    "        print (x)\n",
    "\n",
    "        \n",
    "    ## Naive Bayes Classifier\n",
    "    nb_model = MultinomialNB()\n",
    "    fitted_data = nb_model.fit(train_fit, y_train)\n",
    "    yhat_nb = nb_model.predict(test_features)\n",
    "    prob_nb = nb_model.predict_proba(test_features)\n",
    "    \n",
    "    print (nb_model)\n",
    "    print (\"Precision Score: {0}\".format(precision_score(y_test, yhat_nb)))\n",
    "    print (\"Recall Score: {0}\".format(recall_score(y_test, yhat_nb)))\n",
    "    print (\"AUC Score: {0}\".format(roc_auc_score(y_test, yhat_nb)))\n",
    "    print (\"Model Score:{0}\".format(nb_model.score(test_features, y_test)))\n",
    "\n",
    "    fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, prob_nb[:,1])\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    lr_model = LogisticRegression()\n",
    "    fitted_data = lr_model.fit(train_fit, y_train)\n",
    "    yhat_lr = lr_model.predict(test_features)\n",
    "    prob_lr = lr_model.predict_proba(test_features)\n",
    "    \n",
    "    print (lr_model)\n",
    "    print (\"Precision Score: {0}\".format(precision_score(y_test, yhat_lr)))\n",
    "    print (\"Recall Score: {0}\".format(recall_score(y_test, yhat_lr)))\n",
    "    print (\"AUC Score: {0}\".format(roc_auc_score(y_test, yhat_lr)))\n",
    "    print (\"Model Score:{0}\".format(lr_model.score(test_features, y_test)))\n",
    "\n",
    "    fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, prob_lr[:,1])\n",
    "        \n",
    "    \n",
    "    # ROC Curve\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.plot(np.array(range(101))/100, np.array(range(101))/100, '--', color='black')\n",
    "    plt.plot(fpr, tpr, label='rf-tfidf')\n",
    "    plt.plot(fpr_nb, tpr_nb, label='Naive Bayes')\n",
    "    plt.plot(fpr_lr, tpr_lr, label='Logistic')\n",
    "    plt.ylabel(\"True Positive Rate \")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.title(\"ROC plot\")\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 1\n",
    "rf_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftech1 = preprocess_df(dftech1)\n",
    "rf_predict(dftech1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfh = preprocess_df(dfh)\n",
    "rf_predict(dfh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfht = preprocess_df(dfht)\n",
    "rf_predict(dfht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all2 = preprocess_df(df_all2)\n",
    "rf_predict(df_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftech_all = preprocess_df(dftech_all)\n",
    "rf_predict(dftech_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with 3 grams\n",
    "\n",
    "df_all2 = preprocess_df(df_all2)\n",
    "rf_predict(df_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with 3 grams and Adding Naive Bayes and Logistic Regression\n",
    "\n",
    "df_all2 = preprocess_df(df_all2)\n",
    "rf_predict(df_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftech_all = preprocess_df(dftech_all)\n",
    "rf_predict(dftech_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = {'Weights':weights,\n",
    "        'Labels':labels}\n",
    "\n",
    "\n",
    "\n",
    "featdf = pd.DataFrame(data, columns = ['Weights', 'Features'])\n",
    "\n",
    "featdf.plot(kind='bar', x=featdf['Weights'], fontsize=14, figsize=(8, 5), legend=False)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({'score':np.random.randn(6),\n",
    "#                    'person':[x*3 for x in list('ABCDEF')]})\n",
    "\n",
    "# ax = plt.subplot(111)\n",
    "# df.score.plot(ax=ax, kind='barh', color=list('rgbkym'), title='ranking')\n",
    "# ax.axis('off')\n",
    "# for i, x in enumerate(df.person):\n",
    "#     ax.text(0, i + .5, x, ha='right', fontsize='large')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Printing out the Random Forest Tree\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['summary'], df['class'], test_size=0.3, random_state=0)\n",
    "vectorizer = CountVectorizer(analyzer = 'word', tokenizer = tokenize, ngram_range=(1,4), stop_words = stopwords, max_df = 0.7, min_df = 5, max_features = 5000)\n",
    "train_fit = vectorizer.fit_transform(X_train)\n",
    "train_fit = train_fit.toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "print (\"Training the random forest...\")\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(train_fit, y_train)\n",
    "\n",
    "# Testing\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "#test_data_features = vectorizer.transform(X_test)\n",
    "test_features = vectorizer.transform(X_test)\n",
    "test_features = test_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "yhat = forest.predict(test_features)\n",
    "probX = forest.predict_proba(test_features)\n",
    "\n",
    "print (\"Precision Score: {0}\".format(precision_score(y_test, yhat)))\n",
    "print (\"Recall Score: {0}\".format(recall_score(y_test, yhat)))\n",
    "print (\"AUC Score: {0}\".format(roc_auc_score(y_test, yhat)))\n",
    "print (\"Model Score:{0}\".format(forest.score(test_features, y_test)))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probX[:,1])    \n",
    "\n",
    "# Most important features\n",
    "num = 50\n",
    "imp = forest.feature_importances_\n",
    "feature_names = np.array(feature_names)\n",
    "features = feature_names[np.argsort(imp)[-num:]]\n",
    "weights = imp[np.argsort(imp)[-num:]]\n",
    "feats_with_vals = zip(features, weights)\n",
    "print (\"Top 50 Features\\n\")\n",
    "for x in feats_with_vals:\n",
    "    print (x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
