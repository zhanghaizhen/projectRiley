{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from HTMLParser import HTMLParser\n",
    "import datetime\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File with gender included\n",
    "sample10_file = '/Users/lekha/galvanize/capstone/projectRiley/data/sample10/out.txt'\n",
    "sample1000_file = '/Users/lekha/galvanize/capstone/projectRiley/data/cleandatagender1000.txt'\n",
    "all_file = '/Users/lekha/galvanize/capstone/projectRiley/data/cleandatagenderall.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(all_file, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_name</th>\n",
       "      <th>html</th>\n",
       "      <th>summary</th>\n",
       "      <th>counter</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shawn douglas</td>\n",
       "      <td>./00006.html\\n</td>\n",
       "      <td>i am interested in inventing new methods to co...</td>\n",
       "      <td>1</td>\n",
       "      <td>shawn</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>regina nunn</td>\n",
       "      <td>./05111108.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>regina</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>michael mayes</td>\n",
       "      <td>./120394.html\\n</td>\n",
       "      <td>a detail and results oriented professional wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>michael</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>jason obrien</td>\n",
       "      <td>./17obrien.html\\n</td>\n",
       "      <td>accomplished energetic sales professional with...</td>\n",
       "      <td>1</td>\n",
       "      <td>jason</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>kevin kim</td>\n",
       "      <td>./1800sushi.html\\n</td>\n",
       "      <td>1800sushicom is the new online platform for or...</td>\n",
       "      <td>1</td>\n",
       "      <td>kevin</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      full_name                html  \\\n",
       "0           1  shawn douglas      ./00006.html\\n   \n",
       "1           2    regina nunn   ./05111108.html\\n   \n",
       "2           3  michael mayes     ./120394.html\\n   \n",
       "3           5   jason obrien   ./17obrien.html\\n   \n",
       "4           6      kevin kim  ./1800sushi.html\\n   \n",
       "\n",
       "                                             summary  counter first_name  \\\n",
       "0  i am interested in inventing new methods to co...        1      shawn   \n",
       "1                                            missing        1     regina   \n",
       "2  a detail and results oriented professional wit...        1    michael   \n",
       "3  accomplished energetic sales professional with...        1      jason   \n",
       "4  1800sushicom is the new online platform for or...        1      kevin   \n",
       "\n",
       "   gender  \n",
       "0    male  \n",
       "1  female  \n",
       "2    male  \n",
       "3    male  \n",
       "4    male  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 995 entries, 0 to 994\n",
      "Data columns (total 9 columns):\n",
      "full_name       995 non-null object\n",
      "html            995 non-null object\n",
      "summary         995 non-null object\n",
      "first_name      995 non-null object\n",
      "gender          995 non-null object\n",
      "counter         995 non-null float64\n",
      "summ_missing    995 non-null int64\n",
      "summ_words      995 non-null int64\n",
      "y               995 non-null int64\n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 77.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = df_all[['full_name', 'html','summary', 'first_name', 'gender', 'counter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['class'] = np.ones(len(df_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['class'] = df_all['gender'].apply(lambda x: 0 if x == 'female' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>html</th>\n",
       "      <th>summary</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>counter</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shawn douglas</td>\n",
       "      <td>./00006.html\\n</td>\n",
       "      <td>i am interested in inventing new methods to co...</td>\n",
       "      <td>shawn</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regina nunn</td>\n",
       "      <td>./05111108.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>regina</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>michael mayes</td>\n",
       "      <td>./120394.html\\n</td>\n",
       "      <td>a detail and results oriented professional wit...</td>\n",
       "      <td>michael</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jason obrien</td>\n",
       "      <td>./17obrien.html\\n</td>\n",
       "      <td>accomplished energetic sales professional with...</td>\n",
       "      <td>jason</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevin kim</td>\n",
       "      <td>./1800sushi.html\\n</td>\n",
       "      <td>1800sushicom is the new online platform for or...</td>\n",
       "      <td>kevin</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amy chu</td>\n",
       "      <td>./1amychu.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>amy</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>betty evans</td>\n",
       "      <td>./1bettyevans.html\\n</td>\n",
       "      <td>rj evans  associates inc a retained executive ...</td>\n",
       "      <td>betty</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jason cheng</td>\n",
       "      <td>./1jasoncheng.html\\n</td>\n",
       "      <td>studied economics business administration and ...</td>\n",
       "      <td>jason</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jonathan nelson</td>\n",
       "      <td>./1jonnelson.html\\n</td>\n",
       "      <td>i make tools mostly software lowfriction highv...</td>\n",
       "      <td>jonathan</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kelly sullivan</td>\n",
       "      <td>./1kellysullivan.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>kelly</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jinhee lee</td>\n",
       "      <td>./1leejinhee.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>jinhee</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mark davis</td>\n",
       "      <td>./1markdavis1.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>mark</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>michael shepherd</td>\n",
       "      <td>./1michaelshepherd.html\\n</td>\n",
       "      <td>public relations and content marketing profess...</td>\n",
       "      <td>michael</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ben berkman</td>\n",
       "      <td>./1pridedesign.html\\n</td>\n",
       "      <td>landscape design professional with 13 years of...</td>\n",
       "      <td>ben</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sara hill</td>\n",
       "      <td>./1sarahill.html\\n</td>\n",
       "      <td>i specialize in senior level design management...</td>\n",
       "      <td>sara</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>scott wheeler</td>\n",
       "      <td>./1scottwheeler.html\\n</td>\n",
       "      <td>worked in sales and business management since ...</td>\n",
       "      <td>scott</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>terry smith</td>\n",
       "      <td>./1terrysmith.html\\n</td>\n",
       "      <td>overview nearly 30 years experience in enginee...</td>\n",
       "      <td>terry</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>richard johnson</td>\n",
       "      <td>./21stcenturymarketing.html\\n</td>\n",
       "      <td>since 1990 richard johnson has been helping sm...</td>\n",
       "      <td>richard</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>amanda montgomery</td>\n",
       "      <td>./23montgomery.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>amanda</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mujtaba ahmed</td>\n",
       "      <td>./24467.html\\n</td>\n",
       "      <td>undergone intensive training in ic layout engi...</td>\n",
       "      <td>mujtaba</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            full_name                           html  \\\n",
       "0       shawn douglas                 ./00006.html\\n   \n",
       "1         regina nunn              ./05111108.html\\n   \n",
       "2       michael mayes                ./120394.html\\n   \n",
       "3        jason obrien              ./17obrien.html\\n   \n",
       "4           kevin kim             ./1800sushi.html\\n   \n",
       "5             amy chu               ./1amychu.html\\n   \n",
       "6         betty evans           ./1bettyevans.html\\n   \n",
       "7         jason cheng           ./1jasoncheng.html\\n   \n",
       "8     jonathan nelson            ./1jonnelson.html\\n   \n",
       "9      kelly sullivan        ./1kellysullivan.html\\n   \n",
       "10         jinhee lee            ./1leejinhee.html\\n   \n",
       "11         mark davis           ./1markdavis1.html\\n   \n",
       "12   michael shepherd      ./1michaelshepherd.html\\n   \n",
       "13        ben berkman          ./1pridedesign.html\\n   \n",
       "14          sara hill             ./1sarahill.html\\n   \n",
       "15      scott wheeler         ./1scottwheeler.html\\n   \n",
       "16        terry smith           ./1terrysmith.html\\n   \n",
       "17    richard johnson  ./21stcenturymarketing.html\\n   \n",
       "18  amanda montgomery          ./23montgomery.html\\n   \n",
       "19      mujtaba ahmed                 ./24467.html\\n   \n",
       "\n",
       "                                              summary first_name  gender  \\\n",
       "0   i am interested in inventing new methods to co...      shawn    male   \n",
       "1                                             missing     regina  female   \n",
       "2   a detail and results oriented professional wit...    michael    male   \n",
       "3   accomplished energetic sales professional with...      jason    male   \n",
       "4   1800sushicom is the new online platform for or...      kevin    male   \n",
       "5                                             missing        amy  female   \n",
       "6   rj evans  associates inc a retained executive ...      betty  female   \n",
       "7   studied economics business administration and ...      jason    male   \n",
       "8   i make tools mostly software lowfriction highv...   jonathan    male   \n",
       "9                                             missing      kelly  female   \n",
       "10                                            missing     jinhee  female   \n",
       "11                                            missing       mark    male   \n",
       "12  public relations and content marketing profess...    michael    male   \n",
       "13  landscape design professional with 13 years of...        ben    male   \n",
       "14  i specialize in senior level design management...       sara  female   \n",
       "15  worked in sales and business management since ...      scott    male   \n",
       "16  overview nearly 30 years experience in enginee...      terry    male   \n",
       "17  since 1990 richard johnson has been helping sm...    richard    male   \n",
       "18                                            missing     amanda  female   \n",
       "19  undergone intensive training in ic layout engi...    mujtaba  female   \n",
       "\n",
       "    counter  class  \n",
       "0         1      1  \n",
       "1         1      0  \n",
       "2         1      1  \n",
       "3         1      1  \n",
       "4         1      1  \n",
       "5         1      0  \n",
       "6         1      0  \n",
       "7         1      1  \n",
       "8         1      1  \n",
       "9         1      0  \n",
       "10        1      0  \n",
       "11        1      1  \n",
       "12        1      1  \n",
       "13        1      1  \n",
       "14        1      0  \n",
       "15        1      1  \n",
       "16        1      1  \n",
       "17        1      1  \n",
       "18        1      0  \n",
       "19        1      0  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x == 'missing':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Add feature for missing summary\n",
    "df_all['summ_missing'] = df_all['summary'].apply(lambda x: f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>html</th>\n",
       "      <th>summary</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>counter</th>\n",
       "      <th>class</th>\n",
       "      <th>summ_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shawn douglas</td>\n",
       "      <td>./00006.html\\n</td>\n",
       "      <td>i am interested in inventing new methods to co...</td>\n",
       "      <td>shawn</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regina nunn</td>\n",
       "      <td>./05111108.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>regina</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>michael mayes</td>\n",
       "      <td>./120394.html\\n</td>\n",
       "      <td>a detail and results oriented professional wit...</td>\n",
       "      <td>michael</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jason obrien</td>\n",
       "      <td>./17obrien.html\\n</td>\n",
       "      <td>accomplished energetic sales professional with...</td>\n",
       "      <td>jason</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevin kim</td>\n",
       "      <td>./1800sushi.html\\n</td>\n",
       "      <td>1800sushicom is the new online platform for or...</td>\n",
       "      <td>kevin</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_name                html  \\\n",
       "0  shawn douglas      ./00006.html\\n   \n",
       "1    regina nunn   ./05111108.html\\n   \n",
       "2  michael mayes     ./120394.html\\n   \n",
       "3   jason obrien   ./17obrien.html\\n   \n",
       "4      kevin kim  ./1800sushi.html\\n   \n",
       "\n",
       "                                             summary first_name  gender  \\\n",
       "0  i am interested in inventing new methods to co...      shawn    male   \n",
       "1                                            missing     regina  female   \n",
       "2  a detail and results oriented professional wit...    michael    male   \n",
       "3  accomplished energetic sales professional with...      jason    male   \n",
       "4  1800sushicom is the new online platform for or...      kevin    male   \n",
       "\n",
       "   counter  class  summ_missing  \n",
       "0        1      1             0  \n",
       "1        1      0             1  \n",
       "2        1      1             0  \n",
       "3        1      1             0  \n",
       "4        1      1             0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18047 entries, 0 to 18046\n",
      "Data columns (total 8 columns):\n",
      "full_name       18047 non-null object\n",
      "html            18047 non-null object\n",
      "summary         18040 non-null object\n",
      "first_name      18043 non-null object\n",
      "gender          18047 non-null object\n",
      "counter         18047 non-null float64\n",
      "class           18047 non-null int64\n",
      "summ_missing    18047 non-null int64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i am interested in inventing new methods to co...\n",
       "1                                                  missing\n",
       "2        a detail and results oriented professional wit...\n",
       "3        accomplished energetic sales professional with...\n",
       "4        1800sushicom is the new online platform for or...\n",
       "5                                                  missing\n",
       "6        rj evans  associates inc a retained executive ...\n",
       "7        studied economics business administration and ...\n",
       "8        i make tools mostly software lowfriction highv...\n",
       "9                                                  missing\n",
       "10                                                 missing\n",
       "11                                                 missing\n",
       "12       public relations and content marketing profess...\n",
       "13       landscape design professional with 13 years of...\n",
       "14       i specialize in senior level design management...\n",
       "15       worked in sales and business management since ...\n",
       "16       overview nearly 30 years experience in enginee...\n",
       "17       since 1990 richard johnson has been helping sm...\n",
       "18                                                 missing\n",
       "19       undergone intensive training in ic layout engi...\n",
       "20                                                 missing\n",
       "21                                                 missing\n",
       "22       as ux designer i use the power of design and a...\n",
       "23       nonprofit ngo leadership and community buildin...\n",
       "24                                                 missing\n",
       "25       change is the one great constant in life thats...\n",
       "26       fifteen years of editorial experience includin...\n",
       "27       currently i am working at seattle public schoo...\n",
       "28                                                 missing\n",
       "29       specialtiesmasters of science in information a...\n",
       "                               ...                        \n",
       "18017                                              missing\n",
       "18018    \\tbusiness development customize consulting se...\n",
       "18019                                              missing\n",
       "18020    im an engineer and scientific researcher with ...\n",
       "18021    kevin is a software engineer who is focused on...\n",
       "18022    software engineer with five years of experienc...\n",
       "18023                                              missing\n",
       "18024                                              missing\n",
       "18025    student whos aiming to maximize his potential ...\n",
       "18026                                              missing\n",
       "18027    zlatkofilipoviccom  zfilipovgmailcom 10 years ...\n",
       "18028                   httpcargocollectivecomzoelehryates\n",
       "18029                                              missing\n",
       "18030    specialtiescontent analysis metadata taxonomyo...\n",
       "18031    specialtiescommunications sales publicity prom...\n",
       "18032                                              missing\n",
       "18033    i grew up in the california bay area before mo...\n",
       "18034    i am a dedicated social media community manage...\n",
       "18035                                              missing\n",
       "18036    energetic forward thinking innovative project ...\n",
       "18037    dr nyiri joined the faculty of the department ...\n",
       "18038    i am an entrepreneur and seasoned business pro...\n",
       "18039                                              missing\n",
       "18040                                              missing\n",
       "18041                                              missing\n",
       "18042    zuri rose is a natural networker is a selfstar...\n",
       "18043    i was 14 years old and a freshman in high scho...\n",
       "18044                                              missing\n",
       "18045    detailoriented selfdriven and creative practit...\n",
       "18046    ive designed for globally recognized brands in...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add feature for num of words in the summary\n",
    "def lenx(mystr):\n",
    "    return len(mystr.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['summ_words'] = df_all['summary'].apply(lambda x: lenx(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>html</th>\n",
       "      <th>summary</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>counter</th>\n",
       "      <th>class</th>\n",
       "      <th>summ_missing</th>\n",
       "      <th>summ_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shawn douglas</td>\n",
       "      <td>./00006.html\\n</td>\n",
       "      <td>i am interested in inventing new methods to co...</td>\n",
       "      <td>shawn</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regina nunn</td>\n",
       "      <td>./05111108.html\\n</td>\n",
       "      <td>missing</td>\n",
       "      <td>regina</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>michael mayes</td>\n",
       "      <td>./120394.html\\n</td>\n",
       "      <td>a detail and results oriented professional wit...</td>\n",
       "      <td>michael</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jason obrien</td>\n",
       "      <td>./17obrien.html\\n</td>\n",
       "      <td>accomplished energetic sales professional with...</td>\n",
       "      <td>jason</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevin kim</td>\n",
       "      <td>./1800sushi.html\\n</td>\n",
       "      <td>1800sushicom is the new online platform for or...</td>\n",
       "      <td>kevin</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_name                html  \\\n",
       "0  shawn douglas      ./00006.html\\n   \n",
       "1    regina nunn   ./05111108.html\\n   \n",
       "2  michael mayes     ./120394.html\\n   \n",
       "3   jason obrien   ./17obrien.html\\n   \n",
       "4      kevin kim  ./1800sushi.html\\n   \n",
       "\n",
       "                                             summary first_name  gender  \\\n",
       "0  i am interested in inventing new methods to co...      shawn    male   \n",
       "1                                            missing     regina  female   \n",
       "2  a detail and results oriented professional wit...    michael    male   \n",
       "3  accomplished energetic sales professional with...      jason    male   \n",
       "4  1800sushicom is the new online platform for or...      kevin    male   \n",
       "\n",
       "   counter  class  summ_missing  summ_words  \n",
       "0        1      1             0          25  \n",
       "1        1      0             1           1  \n",
       "2        1      1             0          76  \n",
       "3        1      1             0          55  \n",
       "4        1      1             0         173  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      11071\n",
       "female     6976\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12185\n",
       "1     5862\n",
       "Name: summ_missing, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.summ_missing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dfs for females and males\n",
    "# subset the data by taking the most common names that can be more or less guaranteed to be the gender they claim to be\n",
    "# high level analysis on the number of words used by males and females\n",
    "females = df_all[df_all['gender'] == 'female']\n",
    "males = df_all[df_all['gender'] == 'male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summ_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>66.402236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>76.896125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        summ_words\n",
       "gender            \n",
       "female   66.402236\n",
       "male     76.896125"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby('gender').agg({'summ_words':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summ_missing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>2511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>3351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        summ_missing\n",
       "gender              \n",
       "female          2511\n",
       "male            3351"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.groupby('gender').agg({'summ_missing':sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3599483944954128"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage summary missing\n",
    "female_summaries = 2511/6976.\n",
    "female_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30268268449101254"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_summaries = 3351/11071\n",
    "male_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "2393\n"
     ]
    }
   ],
   "source": [
    "# unique names in females and males\n",
    "print females['first_name'].nunique()\n",
    "print males['first_name'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_df2 = df_all[df_all['summ_missing'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(summary_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>html</th>\n",
       "      <th>summary</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>counter</th>\n",
       "      <th>class</th>\n",
       "      <th>summ_missing</th>\n",
       "      <th>summ_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shawn douglas</td>\n",
       "      <td>./00006.html\\n</td>\n",
       "      <td>i am interested in inventing new methods to co...</td>\n",
       "      <td>shawn</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>michael mayes</td>\n",
       "      <td>./120394.html\\n</td>\n",
       "      <td>a detail and results oriented professional wit...</td>\n",
       "      <td>michael</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jason obrien</td>\n",
       "      <td>./17obrien.html\\n</td>\n",
       "      <td>accomplished energetic sales professional with...</td>\n",
       "      <td>jason</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevin kim</td>\n",
       "      <td>./1800sushi.html\\n</td>\n",
       "      <td>1800sushicom is the new online platform for or...</td>\n",
       "      <td>kevin</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>betty evans</td>\n",
       "      <td>./1bettyevans.html\\n</td>\n",
       "      <td>rj evans  associates inc a retained executive ...</td>\n",
       "      <td>betty</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_name                  html  \\\n",
       "0  shawn douglas        ./00006.html\\n   \n",
       "2  michael mayes       ./120394.html\\n   \n",
       "3   jason obrien     ./17obrien.html\\n   \n",
       "4      kevin kim    ./1800sushi.html\\n   \n",
       "6    betty evans  ./1bettyevans.html\\n   \n",
       "\n",
       "                                             summary first_name  gender  \\\n",
       "0  i am interested in inventing new methods to co...      shawn    male   \n",
       "2  a detail and results oriented professional wit...    michael    male   \n",
       "3  accomplished energetic sales professional with...      jason    male   \n",
       "4  1800sushicom is the new online platform for or...      kevin    male   \n",
       "6  rj evans  associates inc a retained executive ...      betty  female   \n",
       "\n",
       "   counter  class  summ_missing  summ_words  \n",
       "0        1      1             0          25  \n",
       "2        1      1             0          76  \n",
       "3        1      1             0          55  \n",
       "4        1      1             0         173  \n",
       "6        1      0             0         101  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      7720\n",
       "female    4465\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df2.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(my_str):\n",
    "    words = my_str.split()\n",
    "    words = [w for w in words if not w in stopwords]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = summary_df2['summary'].apply(lambda x:get_vocab(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_vocab = []\n",
    "for row in vocab:\n",
    "    for word in row:\n",
    "        all_vocab.append(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_set = set(all_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76964"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      7720\n",
       "female    4465\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df2.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a basic vocabulary look at males and females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_vocab = females['summary'].apply(lambda x:get_vocab(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35370"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_all_vocab = []\n",
    "for row in f_vocab:\n",
    "    for word in row:\n",
    "        f_all_vocab.append(word)\n",
    "        \n",
    "f_vocab_set = set(f_all_vocab)\n",
    "len(f_vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_vocab = males['summary'].apply(lambda x:get_vocab(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57951"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_all_vocab = []\n",
    "for row in m_vocab:\n",
    "    for word in row:\n",
    "        m_all_vocab.append(word)\n",
    "        \n",
    "m_vocab_set = set(m_all_vocab)\n",
    "len(m_vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_words = intersect(f_vocab_set, m_vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16357"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "summary_df2['summary'] = summary_df2['summary'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A basic prediction algorithm to predict gender using summary using RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(summary_df2['summary'], summary_df2['class'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.array(y_test)\n",
    "\n",
    "len(temp[(temp == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-de79327924ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# into feature vectors. The input to fit_transform should be a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_data_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Numpy arrays are easy to work with, so convert the result to an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 804\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 236\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    117\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 5000)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'10', u'100', u'1000', u'10000', u'10th', u'11', u'12', u'1200', u'125', u'13', u'14', u'15', u'150', u'16', u'17', u'1760', u'18', u'1877', u'19', u'1983', u'1985', u'1987', u'1989', u'1990', u'1991', u'1994', u'1995', u'1996', u'1998', u'1999', u'20', u'200', u'2000', u'20000', u'2001', u'2002', u'2003', u'2004', u'2005', u'2006', u'2007', u'2008', u'2009', u'2010', u'2011', u'2012', u'2013', u'2013the', u'2014', u'2014completed', u'2015', u'22', u'23', u'25', u'26', u'2d', u'30', u'300', u'35', u'360', u'3d', u'3rd', u'40', u'45', u'46', u'50', u'500', u'501c3', u'5yrs', u'60', u'70', u'700', u'80', u'ab', u'aba', u'abilities', u'ability', u'able', u'about', u'above', u'abroad', u'abuse', u'academia', u'academic', u'academy', u'accelerate', u'accelerator', u'accenture', u'accepted', u'access', u'accessibility', u'accomplished', u'accomplishment', u'according', u'account', u'accountability', u'accountable', u'accountant', u'accountants', u'accounting', u'accounts', u'accuracy', u'accurate', u'accurately', u'achieve', u'achieved', u'achievement', u'achievements', u'achiever', u'achieving', u'acknowledged', u'acquired', u'acquisition', u'acquisitions', u'across', u'acrylic', u'act', u'acting', u'action', u'actionable', u'actionoriented', u'actions', u'active', u'actively', u'activities', u'activity', u'actor', u'actually', u'acumen', u'acute', u'ad', u'adapt', u'adaptable', u'adapting', u'adaptive', u'add', u'addition', u'additional', u'additionally', u'address', u'addressed', u'addressing', u'adept', u'adjunct', u'administered', u'administration', u'administrative', u'administrator', u'admission', u'admissions', u'admitted', u'adobe', u'adopt', u'adopted', u'adoption', u'adp', u'adps', u'adult', u'adults', u'advance', u'advanced', u'advancing', u'advantage', u'adventure', u'advertising', u'advice', u'advise', u'advised', u'advises', u'advising', u'advisor', u'advisory', u'advocacy', u'advocate', u'advocating', u'aerospace', u'affairs', u'affect', u'affiliate', u'affiliated', u'affiliates', u'afforded', u'afghans', u'africa', u'african', u'after', u'again', u'against', u'age', u'agencies', u'agency', u'agenda', u'agent', u'agents', u'ages', u'agile', u'aging', u'agreements', u'agriculture', u'ai', u'aim', u'air', u'alaska', u'album', u'algorithms', u'aligning', u'alignment', u'alixpartners', u'all', u'alliances', u'allocation', u'allow', u'allows', u'alone', u'along', u'als', u'also', u'alternative', u'although', u'alumni', u'always', u'am', u'amazing', u'amazon', u'ambition', u'ambitious', u'ambush', u'america', u'american', u'americas', u'among', u'amongst', u'amount', u'an', u'analyses', u'analysis', u'analyst', u'analytic', u'analytical', u'analytics', u'analyze', u'analyzing', u'anchor', u'ancient', u'and', u'andor', u'android', u'angeles', u'angularjs', u'animation', u'annual', u'another', u'answer', u'ansys', u'anthropology', u'antonio', u'anxiety', u'any', u'anyone', u'anything', u'anza', u'apache', u'apart', u'app', u'appeal', u'appeals', u'appear', u'appearances', u'appeared', u'applicants', u'application', u'applications', u'applied', u'apply', u'applying', u'appointed', u'appointment', u'approach', u'approaches', u'appropriate', u'approximately', u'apps', u'april', u'aptitude', u'aquatic', u'architect', u'architecting', u'architectural', u'architecture', u'are', u'area', u'areas', u'arena', u'arizona', u'armed', u'arms', u'army', u'arnp', u'around', u'arrangements', u'array', u'arshi', u'art', u'article', u'articles', u'articulate', u'artist', u'artistic', u'artists', u'arts', u'as', u'asia', u'asiapacific', u'aspect', u'aspects', u'aspiring', u'aspnet', u'assays', u'assembly', u'assessing', u'assessment', u'assessments', u'assets', u'assigned', u'assignments', u'assist', u'assistance', u'assistant', u'assisted', u'assisting', u'assists', u'associate', u'associated', u'association', u'associations', u'assurance', u'at', u'athlete', u'athletes', u'athletic', u'atlanta', u'atlas', u'att', u'attain', u'attend', u'attending', u'attention', u'attitude', u'attorney', u'attorneys', u'attributes', u'audience', u'audiences', u'audio', u'audit', u'auditing', u'auditor', u'audits', u'aus', u'austin', u'australia', u'australian', u'author', u'authored', u'authorities', u'authority', u'autocad', u'automated', u'automation', u'automotive', u'available', u'avid', u'award', u'awarded', u'awards', u'awardwinning', u'awareness', u'away', u'azure', u'b2b', u'ba', u'bachelor', u'bachelors', u'back', u'backbone', u'backend', u'background', u'bad', u'badminton', u'baker', u'balance', u'balanced', u'bank', u'banking', u'banks', u'bar', u'barbelo', u'barone', u'barriers', u'base', u'based', u'basic', u'basically', u'basil', u'basis', u'basketball', u'bass', u'bat', u'bats', u'battery', u'bay', u'bcis', u'be', u'beach', u'bear', u'beautiful', u'beauty', u'became', u'because', u'become', u'becoming', u'been', u'before', u'began', u'begin', u'behalf', u'behavior', u'behavioral', u'behaviors', u'behaviour', u'behind', u'being', u'believe', u'believer', u'believes', u'bell', u'bellevue', u'below', u'belt', u'bench', u'benefit', u'benefits', u'berkeley', u'berlin', u'best', u'beta', u'better', u'between', u'beverage', u'beyond', u'bible', u'big', u'biggest', u'bill', u'billing', u'billion', u'biochemistry', u'biodiversity', u'bioengineering', u'bioidentical', u'biological', u'biology', u'biomedical', u'biostatistics', u'biotechnology', u'biz', u'black', u'blend', u'blends', u'block', u'blog', u'blogger', u'blogging', u'blogs', u'blood', u'board', u'boarding', u'boards', u'bodies', u'body', u'boeing', u'bond', u'bono', u'book', u'books', u'boomer', u'born', u'boston', u'botanic', u'both', u'bothell', u'botox', u'bottom', u'boutique', u'box', u'boxing', u'bp', u'brain', u'brainstorming', u'brand', u'branding', u'brands', u'brazil', u'breadth', u'break', u'bribi', u'bridge', u'bridging', u'brief', u'bring', u'bringing', u'brings', u'british', u'broad', u'broadcasters', u'brochures', u'broker', u'brokerage', u'brokers', u'bs', u'bsc', u'bubbleator', u'budget', u'budgeting', u'budgets', u'build', u'builder', u'builders', u'building', u'built', u'bureau', u'business', u'businesses', u'businessspecialties', u'but', u'buy', u'buyers', u'buying', u'by', u'ca', u'cabinets', u'cable', u'cad', u'caia', u'cairo', u'caitlin', u'california', u'californias', u'call', u'called', u'cameroon', u'camp', u'campaign', u'campaigns', u'campus', u'can', u'canada', u'canadian', u'cancer', u'candidate', u'candor', u'cant', u'capabilities', u'capability', u'capable', u'capacities', u'capacity', u'capital', u'captain', u'captive', u'capture', u'car', u'card', u'cardiovascular', u'care', u'career', u'careers', u'carmel', u'carol', u'carolina', u'carried', u'casco', u'case', u'cases', u'cash', u'catalyst', u'catering', u'cathedral', u'catholic', u'causes', u'cbs', u'cc', u'cecilia', u'cell', u'cells', u'cellular', u'center', u'centered', u'centers', u'central', u'centre', u'ceo', u'ceos', u'cerner', u'certificate', u'certification', u'certifications', u'certified', u'cfa', u'cfo', u'cfos', u'chain', u'chair', u'chaired', u'chairman', u'challenge', u'challenges', u'challenging', u'chamber', u'chambers', u'champion', u'championing', u'championships', u'change', u'changes', u'changing', u'channel', u'channels', u'chapter', u'characterization', u'characterized', u'charina', u'charitable', u'charities', u'charlotte', u'check', u'chef', u'chefs', u'chemical', u'chemistry', u'chevron', u'chicago', u'chief', u'child', u'children', u'childrens', u'china', u'chinese', u'choice', u'choral', u'chose', u'chris', u'chronic', u'church', u'churches', u'cincinnati', u'circuit', u'circuits', u'circumstances', u'cisco', u'citation', u'citations', u'cities', u'citizen', u'citizens', u'citizenship', u'citrix', u'city', u'civic', u'civil', u'civilian', u'claims', u'clamp', u'clarify', u'class', u'classes', u'classical', u'classroom', u'clean', u'cleaning', u'clear', u'clevel', u'cleveland', u'client', u'clientele', u'clientfocused', u'clients', u'clientserver', u'climate', u'clinic', u'clinical', u'clinically', u'close', u'closely', u'closet', u'closets', u'closing', u'cloud', u'cloudbased', u'cloudera', u'club', u'clubs', u'cms', u'cnn', u'coach', u'coaches', u'coaching', u'coalition', u'coast', u'coastal', u'coauthor', u'coauthored', u'cochair', u'code', u'coding', u'coffee', u'cognitive', u'coin', u'collaborate', u'collaborating', u'collaboration', u'collaborations', u'collaborative', u'collaboratively', u'collaborator', u'collateral', u'colleague', u'colleagues', u'collection', u'collections', u'college', u'colleges', u'collegiate', u'color', u'colors', u'columbia', u'column', u'combat', u'combination', u'combine', u'combined', u'combining', u'come', u'comedy', u'comfort', u'comfortable', u'comics', u'command', u'commentaries', u'commerce', u'commercial', u'commercialization', u'commitment', u'committed', u'committee', u'committees', u'common', u'communicate', u'communicating', u'communication', u'communications', u'communicator', u'communities', u'community', u'communitybased', u'companies', u'company', u'compassionate', u'compelling', u'compensation', u'competencies', u'competing', u'competition', u'competitive', u'compiling', u'complement', u'complete', u'completed', u'completing', u'completion', u'complex', u'compliance', u'complicated', u'comply', u'component', u'composer', u'composition', u'comprehensive', u'compression', u'computational', u'computer', u'computers', u'computing', u'concentrated', u'concentrates', u'concentration', u'concept', u'concepts', u'conceptual', u'concerned', u'concerns', u'concert', u'concise', u'concrete', u'concur', u'concurrent', u'concurs', u'conditioning', u'conditions', u'conduct', u'conducted', u'conducting', u'conductor', u'conference', u'conferences', u'confidence', u'confident', u'configuration', u'conflict', u'conflicting', u'conflicts', u'confocal', u'congressional', u'connect', u'connected', u'connecting', u'connections', u'consecutive', u'consensus', u'conservation', u'consistent', u'consistently', u'consortium', u'constant', u'constantly', u'constituents', u'construction', u'consultancy', u'consultant', u'consultants', u'consultation', u'consultative', u'consulted', u'consulting', u'consumer', u'consumers', u'contact', u'contemporary', u'content', u'context', u'continents', u'continually', u'continue', u'continued', u'continues', u'continuing', u'continuous', u'contract', u'contracting', u'contractor', u'contracts', u'contribute', u'contributed', u'contributing', u'contribution', u'contributor', u'control', u'controlled', u'controller', u'controllers', u'controls', u'conversation', u'conversations', u'convinced', u'coo', u'cooperative', u'coordinate', u'coordinating', u'coordination', u'coordinator', u'copy', u'copywriter', u'copywriting', u'core', u'cores', u'corp', u'corporate', u'corporation', u'corporations', u'corps', u'corrections', u'correspondence', u'cosmetic', u'cost', u'costs', u'cotn', u'could', u'coulter', u'council', u'counseling', u'counselor', u'counter', u'countries', u'country', u'county', u'coupled', u'courage', u'course', u'courses', u'coursework', u'court', u'coverage', u'covers', u'cowanellsberry', u'coworkers', u'cox', u'cpa', u'cpc', u'craft', u'crafts', u'cream', u'create', u'created', u'creates', u'creating', u'creation', u'creative', u'creativity', u'creator', u'credit', u'credits', u'creek', u'criminal', u'criminology', u'crisis', u'critical', u'criticism', u'crm', u'cross', u'crosscultural', u'crossfunctional', u'crowdfunding', u'crown', u'cruz', u'cryptography', u'crystal', u'csmr', u'css', u'css3', u'csuite', u'cultivating', u'cultural', u'culturally', u'culture', u'cultures', u'cum', u'current', u'currently', u'curriculum', u'custom', u'customer', u'customerfocused', u'customers', u'customized', u'cut', u'cutting', u'cuttingedge', u'cxo', u'cycle', u'cyt', u'daca', u'daily', u'damage', u'dan', u'dana', u'dance', u'dark', u'data', u'database', u'databases', u'datadriven', u'date', u'dave', u'david', u'day', u'days', u'daytoday', u'dc', u'de', u'deadlines', u'deal', u'dealing', u'deals', u'dealt', u'dean', u'death', u'debate', u'debut', u'decade', u'decades', u'decided', u'decision', u'decisionmaking', u'decisions', u'dedicated', u'dedicating', u'dedication', u'deep', u'deeply', u'defense', u'define', u'defined', u'definition', u'degree', u'degrees', u'delayed', u'deliver', u'deliverables', u'delivered', u'deliveries', u'delivering', u'delivery', u'deloitte', u'dem', u'demand', u'demanding', u'democratic', u'demonstrated', u'demonstrates', u'dental', u'dentofacial', u'department', u'departments', u'deploying', u'deployment', u'depth', u'der', u'described', u'design', u'designed', u'designer', u'designers', u'designing', u'designs', u'desire', u'desktop', u'detail', u'detailed', u'details', u'determination', u'dev', u'develop', u'developed', u'developer', u'developers', u'developing', u'development', u'developmentally', u'developmenti', u'develops', u'device', u'devices', u'devoted', u'diamond', u'didnt', u'die', u'diet', u'difference', u'different', u'difficult', u'digital', u'diligence', u'diplomacy', u'direct', u'directed', u'directing', u'direction', u'directly', u'director', u'directors', u'directory', u'disabilities', u'disability', u'disadvantaged', u'disasters', u'discharge', u'discipleship', u'disciplinary', u'discipline', u'disciplined', u'disciplines', u'discover', u'discovery', u'discussing', u'discussion', u'disease', u'disinfection', u'disney', u'disorder', u'disorders', u'dispatch', u'disputes', u'dissertation', u'distinguish', u'distinguished', u'distressed', u'distribute', u'distributed', u'distribution', u'district', u'diverse', u'diversity', u'diving', u'division', u'divisions', u'divorce', u'do', u'doctor', u'doctoral', u'doctorate', u'document', u'documentation', u'documented', u'documents', u'dod', u'doer', u'doering', u'does', u'doing', u'dol', u'dollar', u'dollars', u'domain', u'domains', u'domestic', u'domestically', u'done', u'donelsons', u'donor', u'dont', u'dose', u'double', u'dow', u'down', u'downhill', u'dozens', u'dr', u'draw', u'drawing', u'dreams', u'dreamweaver', u'drive', u'driven', u'drives', u'driving', u'drop', u'drug', u'drums', u'drupal', u'dual', u'dually', u'due', u'during', u'dutch', u'duties', u'duty', u'dvd', u'dynamic', u'dynamics', u'e3', u'each', u'eager', u'early', u'earlystage', u'earn', u'earned', u'earth', u'ease', u'easier', u'easily', u'east', u'eastman', u'easy', u'eat', u'eating', u'ecglp', u'eclectic', u'ecological', u'ecology', u'ecommerce', u'economic', u'economics', u'ecosystem', u'ecuador', u'edge', u'edinburgh', u'edit', u'editing', u'edition', u'editor', u'editorial', u'editors', u'educate', u'education', u'educational', u'educator', u'edward', u'effect', u'effective', u'effectively', u'effectiveness', u'effects', u'efficiency', u'efficient', u'efficiently', u'effort', u'efforts', u'eg', u'eight', u'either', u'elderly', u'elected', u'election', u'electrical', u'electronic', u'electronics', u'element', u'elements', u'eligible', u'elite', u'emag', u'email', u'embedded', u'emea', u'emergency', u'emerging', u'emotional', u'emphasis', u'employ', u'employed', u'employee', u'employees', u'employer', u'employers', u'employment', u'empowering', u'emse', u'enable', u'enabled', u'enables', u'encompasses', u'encourage', u'encouraged', u'end', u'endtoend', u'enduring', u'enduser', u'energetic', u'energies', u'energy', u'enforcement', u'engage', u'engaged', u'engagement', u'engagements', u'engaging', u'engine', u'engineer', u'engineering', u'engineers', u'england', u'english', u'enhance', u'enhanced', u'enjoy', u'enjoyed', u'enjoying', u'enjoys', u'enough', u'enrolled', u'ensemble', u'ensure', u'ensuring', u'enter', u'enterprise', u'enterprises', u'entertainment', u'enthusiasm', u'enthusiast', u'enthusiastic', u'entire', u'entities', u'entitled', u'entity', u'entrepreneur', u'entrepreneurial', u'entrepreneurship', u'entry', u'environment', u'environmental', u'environments', u'epa', u'epic', u'epidemic', u'epidemiological', u'epidemiology', u'episcopal', u'epstein', u'equal', u'equally', u'equipment', u'equity', u'era', u'erica', u'erick', u'especially', u'essential', u'establish', u'established', u'establishing', u'establishment', u'estate', u'estatei', u'estimating', u'etc', u'eternal', u'ethic', u'ethical', u'ethics', u'ethnic', u'etymology', u'europe', u'european', u'evaluate', u'evaluating', u'evaluation', u'evaluations', u'evaluator', u'evans', u'even', u'event', u'events', u'ever', u'evergreen', u'every', u'everyone', u'everything', u'evidence', u'evidencebased', u'evolution', u'evolving', u'exam', u'examinations', u'examiner', u'example', u'exams', u'excavation', u'exceed', u'exceeding', u'excel', u'excellence', u'excellent', u'excels', u'exceptional', u'exceptionally', u'exchange', u'excited', u'exciting', u'execute', u'executing', u'execution', u'executive', u'executives', u'exercises', u'exhibitions', u'exhibits', u'existing', u'exit', u'expand', u'expanded', u'expanding', u'expansion', u'expectations', u'expected', u'expense', u'expensive', u'experience', u'experience10', u'experienced', u'experiences', u'experiencespecialties', u'experiment', u'experimental', u'experiments', u'expert', u'expertise', u'experts', u'exploiting', u'exploration', u'explore', u'explorer', u'exploring', u'exposure', u'exposures', u'express', u'extensive', u'extensively', u'external', u'extra', u'extremely', u'eye', u'f1', u'f135', u'fabrication', u'face', u'facebook', u'faced', u'facilitate', u'facilitating', u'facilitation', u'facilitator', u'facilities', u'facilitiesengineering', u'facility', u'facing', u'faction', u'faculty', u'fall', u'falmouth', u'familiar', u'families', u'family', u'far', u'fashion', u'fast', u'fastpaced', u'fate', u'favorite', u'fbi', u'fda', u'feasibility', u'feature', u'featured', u'february', u'federal', u'feedback', u'feel', u'felid', u'felids', u'fell', u'fellow', u'fellowship', u'fermentation', u'festivals', u'few', u'fiction', u'fidelity', u'field', u'fields', u'fifteen', u'fightmaster', u'filings', u'film', u'films', u'final', u'finance', u'financial', u'financing', u'find', u'finder', u'finding', u'fine', u'fire', u'firm', u'firms', u'first', u'fishing', u'fit', u'fitness', u'five', u'flagship', u'flash', u'flexibility', u'flexible', u'floral', u'florida', u'flow', u'fluent', u'fluid', u'fluorescence', u'focus', u'focused', u'focuses', u'focusing', u'foe', u'fold', u'folks', u'follow', u'followed', u'following', u'follows', u'food', u'football', u'for', u'force', u'forces', u'forecast', u'forecasting', u'foreign', u'forest', u'forestry', u'forge', u'form', u'formal', u'formation', u'formative', u'formed', u'former', u'formerly', u'forming', u'forms', u'forprofit', u'fortune', u'forum', u'forward', u'foster', u'fostering', u'found', u'foundation', u'foundations', u'founded', u'founder', u'four', u'fox', u'framework', u'frameworks', u'france', u'franchise', u'francisco', u'fraud', u'fred', u'free', u'freelance', u'french', u'frequency', u'frequent', u'frequently', u'fresh', u'friendly', u'friends', u'from', u'front', u'frontend', u'frye', u'fsh', u'fuels', u'fulbright', u'fulfilling', u'full', u'fulltime', u'fully', u'fun', u'function', u'functional', u'functions', u'fund', u'fundamental', u'funding', u'fundraising', u'further', u'furthermore', u'future', u'ga', u'gain', u'gained', u'gaining', u'gallery', u'game', u'games', u'gamification', u'gamma', u'garden', u'gas', u'gastroenterology', u'gathered', u'gender', u'general', u'generally', u'generate', u'generating', u'generation', u'genes', u'genetics', u'geographic', u'geographically', u'geographies', u'geography', u'geoinformation', u'geophysical', u'george', u'georgetown', u'georgia', u'geotechnical', u'german', u'get', u'getting', u'gibbon', u'gibbons', u'gifts', u'gilmore', u'gis', u'give', u'given', u'giving', u'glenn', u'global', u'globalized', u'globally', u'go', u'goal', u'goaloriented', u'goals', u'going', u'gold', u'golden', u'good', u'google', u'got', u'gotomarket', u'gotten', u'governance', u'government', u'governmental', u'governments', u'grad', u'graduate', u'graduated', u'graduating', u'graduation', u'grand', u'grant', u'granted', u'grants', u'graphic', u'graphical', u'graphics', u'gravity', u'grays', u'great', u'greater', u'green', u'grew', u'grid', u'ground', u'group', u'groups', u'grow', u'growing', u'grown', u'growth', u'growthstage', u'gsb', u'guatemala', u'guest', u'guidance', u'guide', u'guidelines', u'guiding', u'guild', u'guitar', u'gulf', u'guy', u'h1b', u'habitat', u'hacking', u'had', u'hadoop', u'hall', u'haltom', u'hancock', u'hand', u'handle', u'handling', u'hands', u'handson', u'happy', u'harbor', u'hard', u'hardware', u'hardworking', u'harvard', u'has', u'hashmi', u'hats', u'have', u'having', u'hawaii', u'hazardous', u'he', u'head', u'headquarters', u'healed', u'healing', u'health', u'healthcare', u'healthy', u'hear', u'hearing', u'heart', u'heather', u'heavy', u'held', u'help', u'helped', u'helping', u'helps', u'henry', u'her', u'here', u'herself', u'hesitate', u'hidden', u'higbee', u'high', u'highenergy', u'higher', u'highest', u'highfrequency', u'highgrowth', u'highimpact', u'highlands', u'highlevel', u'highlights', u'highly', u'highlyskilled', u'highperformance', u'highperforming', u'highquality', u'highspeed', u'highvolume', u'highway', u'him', u'himself', u'himss', u'hiring', u'his', u'historical', u'history', u'hive', u'hold', u'holding', u'holds', u'holistic', u'home', u'homeland', u'homeowners', u'homes', u'hone', u'honor', u'honored', u'honors', u'hope', u'hopes', u'hoping', u'hopkins', u'hormone', u'hospital', u'hospitality', u'hospitals', u'host', u'hosted', u'hosting', u'hot', u'hotels', u'hours', u'house', u'household', u'housing', u'houston', u'how', u'however', u'hp', u'hr', u'hris', u'html', u'html5', u'huffington', u'huge', u'human', u'humanitarian', u'humanities', u'humanity', u'humans', u'humor', u'hunting', u'hydro', u'hyman', u'i9', u'iaas', u'ian', u'ibm', u'ice', u'ich', u'icsm', u'ict', u'id', u'idea', u'ideal', u'ideas', u'ideation', u'identification', u'identify', u'identifying', u'identities', u'identity', u'ie', u'if', u'ii', u'iii', u'il', u'illinois', u'illustration', u'illustrator', u'im', u'image', u'imaging', u'immigrant', u'immigration', u'impact', u'impacts', u'implement', u'implementation', u'implemented', u'implementing', u'implications', u'important', u'impressive', u'improve', u'improved', u'improvement', u'improvements', u'improving', u'in', u'inactive', u'inc', u'incident', u'incidents', u'include', u'included', u'includes', u'including', u'inclusion', u'inclusive', u'income', u'incorporate', u'increase', u'increased', u'increasing', u'increasingly', u'incredible', u'indemnity', u'independent', u'independently', u'indepth', u'indesign', u'india', u'indian', u'indiana', u'indirect', u'individual', u'individually', u'individuals', u'indonesia', u'industrial', u'industries', u'industry', u'influence', u'influencer', u'influencing', u'info', u'informal', u'informatics', u'information', u'informed', u'informing', u'infrastructure', u'infrastructures', u'inhouse', u'initial', u'initiative', u'initiatives', u'injuries', u'injury', u'innate', u'innovate', u'innovating', u'innovation', u'innovations', u'innovative', u'innovator', u'inpatient', u'input', u'insight', u'insights', u'inspections', u'inspiring', u'installation', u'instead', u'institute', u'institution', u'institutional', u'institutions', u'instruction', u'instructional', u'instructor', u'instruments', u'insurance', u'integral', u'integrated', u'integrates', u'integration', u'integrations', u'integrity', u'intellectual', u'intelligence', u'intelligent', u'intend', u'intense', u'interact', u'interaction', u'interactive', u'intercultural', u'interdisciplinary', u'interest', u'interested', u'interesting', u'interests', u'interface', u'interfaces', u'interim', u'interior', u'intermediate', u'intermodal', u'intern', u'internal', u'internat', u'international', u'internationally', u'internet', u'internship', u'internships', u'interpersonal', u'interpretation', u'intervention', u'interview', u'interviewing', u'interviews', u'into', u'introduce', u'introduction', u'intuitive', u'invaluable', u'invented', u'inventor', u'investigating', u'investigation', u'investigations', u'investigator', u'investing', u'investment', u'investments', u'investor', u'investors', u'invited', u'involved', u'involvement', u'involves', u'involving', u'ios', u'ip', u'ipo', u'is', u'islamabad', u'islamic', u'island', u'iso', u'israel', u'issue', u'issues', u'it', u'italian', u'itil', u'its', u'ive', u'j1', u'jacob', u'jag', u'james', u'jamie', u'january', u'japan', u'japanese', u'jason', u'java', u'javascript', u'jazz', u'jd', u'jersey', u'jewish', u'job', u'jobs', u'john', u'johns', u'join', u'joined', u'joining', u'joint', u'jones', u'joseph', u'joshua', u'journal', u'journalism', u'journalist', u'journals', u'journey', u'jquery', u'js', u'jsa', u'jss', u'judy', u'julie', u'july', u'june', u'junior', u'just', u'justice', u'juvenile', u'kaiser', u'karen', u'kazakhstan', u'keen', u'keep', u'keeping', u'kennedy', u'key', u'keynote', u'kim', u'kinds', u'king', u'kingdom', u'kirkland', u'kitchen', u'kiwanis', u'km', u'knack', u'know', u'knowledge', u'knowledgeable', u'known', u'knows', u'korean', u'kpmg', u'kyle', u'l1', u'la', u'lab', u'label', u'labor', u'laboratory', u'labs', u'lakeisha', u'lakes', u'lamp', u'land', u'landing', u'lands', u'landscape', u'landuse', u'lang', u'language', u'languages', u'large', u'larger', u'largescale', u'largest', u'las', u'last', u'lasting', u'late', u'later', u'latest', u'latex', u'latin', u'laude', u'launch', u'launched', u'launches', u'launching', u'laurel', u'law', u'laws', u'lawyers', u'lay', u'layout', u'lca', u'lead', u'leader', u'leaders', u'leadership', u'leading', u'leads', u'league', u'lean', u'learn', u'learned', u'learner', u'learning', u'lease', u'leases', u'least', u'leaving', u'lecture', u'lecturer', u'lectures', u'led', u'lee', u'leed', u'left', u'legacy', u'legal', u'legislation', u'lending', u'length', u'let', u'letters', u'level', u'levels', u'leverage', u'leveraging', u'lewis', u'lgbt', u'liaison', u'libraries', u'library', u'license', u'licensed', u'licensing', u'life', u'lifecycle', u'lifes', u'lifestyle', u'lifestyles', u'light', u'liguang', u'like', u'likely', u'likes', u'limit', u'limited', u'limnology', u'line', u'lines', u'link', u'linkedin', u'linux', u'lis', u'list', u'listen', u'listener', u'listening', u'listing', u'literature', u'litigation', u'litigator', u'little', u'live', u'lived', u'lives', u'livesay', u'living', u'llm', u'local', u'locally', u'locations', u'log', u'logic', u'logistics', u'london', u'long', u'longrange', u'longterm', u'look', u'looking', u'los', u'loss', u'lot', u'lotus', u'love', u'loved', u'loves', u'lower', u'luke', u'luxury', u'lystig', u'ma', u'mac', u'machine', u'machines', u'made', u'magazine', u'magazines', u'mail', u'maine', u'mainframe', u'maintain', u'maintained', u'maintaining', u'maintains', u'major', u'majoring', u'make', u'maker', u'makers', u'makes', u'making', u'malpractice', u'mamr', u'man', u'manage', u'managed', u'management', u'managementhe', u'managementspecialties', u'manager', u'managerial', u'managers', u'managing', u'managment', u'mandarin', u'mangoury', u'manner', u'manuals', u'manufacturing', u'many', u'map', u'maple', u'mapping', u'mapps', u'maps', u'march', u'marine', u'mark', u'markarian', u'markarians', u'market', u'marketer', u'marketers', u'marketing', u'marketplace', u'markets', u'marquette', u'marriage', u'mary', u'maryland', u'massachusetts', u'massive', u'master', u'masters', u'match', u'material', u'materials', u'math', u'mathematica', u'mathematical', u'mathematics', u'matlab', u'matter', u'matters', u'mattone', u'mature', u'maury', u'maximizing', u'may', u'mayo', u'mayor', u'mba', u'mbti', u'mcchin', u'md', u'me', u'mean', u'meaningful', u'meaningfully', u'means', u'measurable', u'measured', u'measurement', u'measuring', u'mechanic', u'mechanical', u'medals', u'media', u'mediation', u'medical', u'medicine', u'medium', u'medtronic', u'meet', u'meeting', u'meetings', u'meiner', u'meines', u'member', u'members', u'membership', u'memory', u'memphis', u'mental', u'mentor', u'mentored', u'mentoring', u'merchandising', u'merge', u'mergers', u'message', u'messaging', u'met', u'metal', u'metaphysics', u'method', u'methodologies', u'methodology', u'methods', u'metrics', u'metro', u'mexico', u'mgmt', u'miami', u'michigan', u'microfinance', u'microscope', u'microscopy', u'microsoft', u'microstructure', u'middle', u'midlevel', u'migrant', u'mike', u'milestones', u'military', u'million', u'millions', u'mind', u'minds', u'mindset', u'minerals', u'mines', u'minimum', u'mining', u'ministry', u'minnesota', u'minor', u'mission', u'missionary', u'missions', u'mit', u'mobile', u'mobility', u'mobilize', u'model', u'modeling', u'modelling', u'models', u'modern', u'modifications', u'molecular', u'molly', u'money', u'monitoring', u'month', u'monthly', u'months', u'montreal', u'monument', u'moral', u'more', u'morning', u'morocco', u'mortgage', u'most', u'mostly', u'mother', u'motion', u'motivate', u'motivated', u'motivating', u'move', u'moved', u'movie', u'movies', u'moving', u'mpa', u'mpls', u'ms', u'msc', u'msn', u'msse', u'mst', u'much', u'multicultural', u'multidisciplinary', u'multifaceted', u'multifamily', u'multimedia', u'multimillion', u'multinational', u'multiplatform', u'multiple', u'multistate', u'multitask', u'multitasking', u'municipal', u'museum', u'music', u'musical', u'musician', u'my', u'myers', u'myself', u'name', u'named', u'nanoparticle', u'nanotechnology', u'narrative', u'nashville', u'nasm', u'nation', u'national', u'nationally', u'nations', u'nationwide', u'native', u'natural', u'nature', u'navigate', u'navy', u'nazka', u'nc', u'ncaa', u'ncc', u'near', u'nearly', u'necessary', u'necessity', u'need', u'needed', u'needs', u'negotiate', u'negotiated', u'negotiating', u'negotiation', u'negotiations', u'neighborhood', u'nepa', u'nerd', u'network', u'networking', u'networks', u'neurology', u'neuroscience', u'never', u'new', u'newest', u'news', u'newsletter', u'newsletters', u'newspapers', u'next', u'nexus', u'ngos', u'nice', u'nichols', u'nick', u'night', u'nightlife', u'nights', u'nih', u'nine', u'nj', u'nlr', u'no', u'nominated', u'nominee', u'non', u'nonimmigrant', u'nonprofit', u'nonprofits', u'nontechnical', u'nordstrom', u'normal', u'north', u'northern', u'northwest', u'northwestern', u'not', u'notes', u'notforprofit', u'nothing', u'novel', u'novels', u'november', u'now', u'npz', u'nrda', u'nuclear', u'number', u'numerous', u'nurse', u'nurses', u'nursing', u'nutrition', u'nutritional', u'ny', u'nycfilm', u'o1', u'oakland', u'oasis', u'obama', u'obesity', u'objective', u'objectivemake', u'objectives', u'objectivescredentials', u'objectivesspecialtieshighly', u'objectoriented', u'objects', u'obligations', u'observations', u'obsessions', u'obsolescence', u'obstacles', u'obstruction', u'obtain', u'obtained', u'obtaining', u'occasional', u'occupational', u'occupied', u'occurs', u'oceanographic', u'oceanography', u'octave', u'odabi', u'odonnell', u'odst', u'oems', u'oemsgoalsto', u'of', u'off', u'offchance', u'offensekull', u'offenses', u'offer', u'offered', u'offering', u'offeringsmy', u'offers', u'office', u'officebiostatistical', u'officer', u'officercompany', u'officers', u'offices', u'officespecialitiessoftware', u'officials', u'offshore', u'often', u'og', u'ohio', u'ohsas', u'oil', u'okanogan', u'oki', u'okumura', u'olaf', u'olap', u'old', u'ollydbg', u'olympia', u'olympics', u'om', u'omak', u'omega', u'omg', u'omnigraffle', u'omniture', u'on', u'onair', u'onalytica', u'onboarding', u'onbudget', u'once', u'oncology', u'oncopanel', u'ondemand', u'one', u'oneman', u'oneonone', u'ones', u'onetoone', u'ongoing', u'online', u'only', u'onshore', u'onsite', u'ontariorick', u'ontime', u'onto', u'ontologiesspecialties', u'opeds', u'open', u'openal', u'openchest', u'opened', u'opengl', u'openhouse', u'opening', u'openings', u'openlook', u'openminded', u'openssl', u'opera', u'operate', u'operates', u'operating', u'operation', u'operational', u'operations', u'operationsprior', u'operationssupply', u'operator', u'opinion', u'opinions', u'opms', u'opportunities', u'opportunitiesfor', u'opportunitiesmost', u'opportunitiesspecialities', u'opportunitiesspecialties', u'opportunity', u'opposite', u'oprah', u'ops', u'optics', u'optimal', u'optimist', u'optimistic', u'optimization', u'optimizationin', u'optimize', u'optimized', u'optimizes', u'optimizing', u'optimum', u'options', u'optionsalthough', u'or', u'oral', u'oramstream', u'orangutan', u'orcad', u'orchestra', u'orchestration', u'orchestrator', u'order', u'orders', u'ordersprojects', u'ordinances', u'ordinary', u'oregon', u'oregons', u'organic', u'organically', u'organisation', u'organisational', u'organisations', u'organised', u'organization', u'organizational', u'organizationfive', u'organizations', u'organizationsaccomplished', u'organizationsi', u'organizationsinterested', u'organizationspartner', u'organizationsresultsdriven', u'organizationsspecialtiesability', u'organizationsspecialtiesmarketing', u'organized', u'organizednatural', u'organizer', u'organizing', u'orientated', u'orientationscomplex', u'oriented', u'original', u'originator', u'orleans', u'orleansim', u'orono', u'orthodontic', u'orthodontics', u'orthodontist', u'orthopedics', u'orthopedicsmotivational', u'oscillator', u'oscilloscopes', u'osg', u'osha', u'ospf', u'ostp', u'osu', u'oswego', u'osx', u'ot', u'other', u'others', u'others10', u'othersi', u'othersin', u'othersinnovation', u'othersmy', u'othersrory', u'otherwisespecialtiesinteraction', u'otolaryngology', u'our', u'ourselves', u'out', u'outcome', u'outcomeoriented', u'outcomes', u'outcomesexpertise', u'outcomesspecialties', u'outdoor', u'outlets', u'outlined', u'outlines', u'outlook', u'outofthebox', u'outperform', u'outplacement', u'outreach', u'outside', u'outsource', u'outsourced', u'outsourcing', u'outspecialties', u'outstanding', u'outwardly', u'over', u'overactive', u'overall', u'overcomes', u'overdeliver', u'overhauls', u'overnight', u'oversaw', u'oversee', u'overseeing', u'overseen', u'oversees', u'oversight', u'overviewing', u'overwhelming', u'owe', u'own', u'owned', u'owner', u'owneradvisory', u'owners', u'ownership', u'owns', u'oxford', u'oxide', u'oxpcgive', u'pa', u'paced', u'pacer', u'pacific', u'pacificcustomerfacing', u'pacifique', u'package', u'packages', u'packaging', u'packard', u'packed', u'packet', u'pacu', u'pads', u'page', u'pageant', u'pageonenow', u'pahowho', u'paid', u'pain', u'paint', u'painter', u'painting', u'paintingwellversed', u'paints', u'paired', u'pakistan', u'pakistandr', u'pakistani', u'paleontology', u'palliative', u'palmas', u'paltz', u'pandas', u'panel', u'panser', u'paper', u'papers', u'papersfrom', u'paraguay', u'paralegal', u'paralegals', u'parallel', u'paralysis', u'parent', u'parenting', u'parents', u'parentsloved', u'paris', u'park', u'parks', u'parkslive', u'parsers', u'parsons', u'part', u'partaking', u'participant', u'participants', u'participate', u'participated', u'participating', u'participation', u'participationspecialties', u'participatory', u'particular', u'particularly', u'parties', u'partner', u'partnerfocused', u'partnering', u'partnern', u'partners', u'partnership', u'partnershipacquisitions', u'partnerships', u'partnershipsshe', u'partnervendor', u'partnerwhy', u'parts', u'parttime', u'parttimer', u'party', u'pasadera', u'pascal', u'pass', u'passed', u'passing', u'passion', u'passionate', u'passionately', u'passions', u'passive', u'past', u'pastors', u'pat', u'patch', u'patent', u'patented', u'patenting', u'patents', u'patentsurface', u'path', u'pathogens', u'pathologist', u'pathology', u'pathways', u'patient', u'patients', u'patrol', u'pats', u'patterson', u'paul', u'paula', u'paved', u'pay', u'payable', u'payment', u'payments', u'payperclick', u'payroll', u'pb', u'pbs', u'pbsdisney', u'pbtsspecialtiesenvironmental', u'pc', u'pcafter', u'pcbsspecialties', u'pcer', u'pcimac', u'pcr', u'pcs', u'pcsenterprise', u'pct', u'pddnos', u'pe', u'peace', u'peacebuildingi', u'peaks', u'pearson', u'peatland', u'pebble', u'pedagogical', u'pederson', u'pedestrian', u'pediatric', u'pediatrics', u'pee', u'peel', u'peels', u'peer', u'peerreviewed', u'peers', u'penchant', u'penetration', u'peninsula', u'penn', u'penns', u'pennsylvania', u'people', u'peoplecentered', u'peopleeducation', u'peopleexperiencemobile', u'peoplemost', u'peopleoriented', u'peoples', u'pepsi', u'per', u'percent', u'perceptions', u'percussion', u'perfect', u'perform', u'performance', u'performancebased', u'performancecompliance', u'performancedriven', u'performancei', u'performanceo', u'performanceobjectivec', u'performances', u'performed', u'performer', u'performers', u'performing', u'perinatal', u'period', u'periodexpansion', u'perioperative', u'perl', u'perm', u'permanent', u'permanente', u'permanete', u'permit', u'permitting', u'pernambucanas', u'perpetrationprior', u'perry', u'persecuted', u'persistence', u'person', u'persona', u'personable', u'personal', u'personalised', u'personalities', u'personality', u'personalized', u'personally', u'personalprofessional', u'personfirst', u'personi', u'personnel', u'persons', u'personspecial', u'personspecialtiesproject', u'perspective', u'perspectiveconfident', u'perspectives', u'persuading', u'persuasive', u'persuasively', u'pertaining', u'pertinent', u'peru', u'pet', u'peter', u'petrobrs', u'petroleum', u'pets', u'pew', u'pfizer', u'pharma', u'pharmaceutical', u'pharmaceuticals', u'pharmacology', u'pharmacy', u'phase', u'phases', u'phd', u'phenomenal', u'phi', u'philadelphia', u'philanthropic', u'philanthropy', u'philanthropyother', u'philippines', u'philippinesworldwide', u'philips', u'phillips', u'philosophy', u'phlebotomy', u'phone', u'phones', u'photo', u'photodeluxe', u'photograhy', u'photographer', u'photographers', u'photographic', u'photography', u'photos', u'photoshop', u'photovideographer', u'php', u'phphtmlcssjquery', u'phr', u'phthalates', u'phulwani', u'physical', u'physically', u'physician', u'physicians', u'physics', u'physicsresearch', u'phytoplankton', u'pianist', u'piano', u'picc', u'picked', u'picture', u'pictures', u'picturing', u'pie', u'pieces', u'pierce', u'pierre', u'piers', u'pig', u'pigment', u'pigments', u'piles', u'pill', u'pillars', u'pilot', u'pincus', u'pioneer', u'pioneering', u'pipe', u'pipeline', u'piston', u'pitching', u'pixasarouterswitch', u'pl', u'place', u'placed', u'placei', u'placement', u'placements', u'places', u'placing', u'plan', u'planet', u'planets', u'planned', u'planner', u'planners', u'planning', u'planningbuying', u'planningimplementing', u'planningsummer', u'plans', u'plant', u'planter', u'plants', u'planview', u'plastic', u'plastics', u'platform', u'platformat', u'platforms', u'platformshardware', u'platformsmedical', u'platformsspecialties', u'plattsburgspecialties', u'play', u'played', u'player', u'players', u'playing', u'playoutside', u'plays', u'please', u'pleasure', u'plenty', u'plight', u'pls', u'plurality', u'plus', u'pm', u'pmbok', u'pmis', u'pmo', u'pmp', u'poem', u'poet', u'poetintheschools', u'poetry', u'point', u'points', u'polarized', u'police', u'policies', u'policiesspecialties', u'policingsubstantive', u'policy', u'policyconsolidationareas', u'policymaking', u'policyspecialties', u'polish', u'politely', u'political', u'politics', u'politiker', u'politikerdynastie', u'politology', u'pollution', u'polymers', u'polytechnique', u'poor', u'pop', u'popular', u'population', u'populationbased', u'populations', u'populationsprincipled', u'populous', u'porosity', u'port', u'portability', u'portal', u'portfolio', u'portfolios', u'porting', u'portion', u'portland', u'portuguese', u'position', u'positioned', u'positioning', u'positions', u'positionspecialties', u'positive', u'positively', u'positivity', u'possess', u'possesses', u'possessing', u'possibilities', u'possibilitiesas', u'possible', u'possiblehighlights', u'possibly', u'post', u'postconflict', u'postcrisis', u'postdoctoral', u'posted', u'poster', u'posters', u'postgraduate', u'postgreat', u'postrob', u'posts', u'postsecondary', u'posttenure', u'posttraumatic', u'potential', u'pow', u'power', u'powerforms', u'powerful', u'powerfully', u'powerhouse', u'powerpoint', u'powers', u'powerscribe', u'pp', u'ppc', u'pr', u'pra', u'practical', u'practicality', u'practice', u'practicea', u'practiced', u'practices', u'practicesdr', u'practicesi', u'practicesspecialties', u'practicethough', u'practicetwitter', u'practicing', u'practitioner', u'practitioners', u'pragmatic', u'prague', u'praise', u'pramong', u'prayer', u'preacher', u'preaches', u'precertified', u'precioustatus', u'precision', u'preclinical', u'predesigned', u'predict', u'predicting', u'predictive', u'preeminent', u'prefer', u'preferable', u'preferably', u'preferconcur', u'preferred', u'preliminary', u'premier', u'premiere', u'premiered', u'premium', u'preparation', u'preparatory', u'prepare', u'prepared', u'preparedness', u'preparing', u'preplastic', u'prepost', u'preproduction', u'prerequisites', u'presales', u'prescription', u'presence', u'present', u'presentation', u'presentations', u'presentationsbright', u'presented', u'presenter', u'presenting', u'presently', u'presents', u'preserve', u'preserving', u'president', u'presidentceo', u'presidentformer', u'presidentmanaging', u'press', u'pressganey', u'pressure', u'pressureability', u'prestigious', u'pretrial', u'prevention', u'preventive', u'previewed', u'previous', u'previously', u'pricing', u'pride', u'prides', u'priester', u'primarily', u'primary', u'primate', u'primates', u'primatology', u'primitive', u'princeton', u'princetons', u'principal', u'principally', u'principles', u'print', u'printershe', u'printing', u'printmaking', u'printspecialtieso', u'printtoweb', u'prior', u'priorities', u'prioritization', u'prioritizing', u'priority', u'pritchard', u'privacy', u'private', u'privatelyheld', u'privatemove', u'privatsekretr', u'privilaged', u'privilege', u'privileged', u'prize', u'prizes', u'pro', u'proactive', u'proactively', u'probabilistic', u'probably', u'probate', u'probation', u'probe', u'probebased', u'problem', u'problems', u'problemsat', u'problemsi', u'problemslisten', u'problemsolve', u'problemsolver', u'problemsolving', u'procedure', u'procedures', u'proceduresa', u'procedurespecialtiesoffice', u'proceedings', u'proceeds', u'process', u'processes', u'processeslooking', u'processeso', u'processing', u'processingauditsresearching', u'processingi', u'procurement', u'produce', u'produced', u'producer', u'producerpublic', u'producing', u'product', u'productcorporate', u'production', u'productiondirecting', u'productionnew', u'productionplanning', u'productions', u'productive', u'productivity', u'productivityat', u'productoriented', u'products', u'productsand', u'productsdemonstrated', u'productsi', u'productsspecialties', u'prof', u'profdr', u'profession', u'professional', u'professionalcreative', u'professionalismspecialties', u'professionally', u'professionals', u'professionalsas', u'professionelle', u'professor', u'professorship', u'professoryale', u'proficiencies', u'proficiency', u'proficiencyability', u'proficiencymicrosoft', u'proficient', u'profile', u'profiled', u'profilemarketing', u'profiler', u'profiles', u'profilesrobust', u'profiling', u'profit', u'profitability', u'profitable', u'profits', u'profitspecialtiescurriculum', u'profound', u'program', u'programi', u'programinvolution', u'programkth', u'programmable', u'programmanaging', u'programme', u'programmer', u'programming', u'programmingspecialitiesstrategic', u'programs', u'programsales', u'programscrisis', u'programsextensive', u'programsin', u'programsinterested', u'programsms', u'programspecialties', u'programsrecovery', u'programssocial', u'programsspecialities', u'programsspecialties', u'programsspecialtiesplanning', u'programstherapeutic', u'progress', u'progressing', u'progressive', u'progressively', u'progressoutside', u'project', u'project411', u'projectcraft', u'projectcurrently', u'projected', u'projectglobal', u'projections', u'projectnew', u'projectportfolio', u'projectprogram', u'projects', u'projects54', u'projectscreatedexecutive', u'projectsinitiating', u'projectsmax', u'projectsnext', u'projectsnicholas', u'projectsoftware', u'projectsprograms', u'projectsspecialtiesbehavioural', u'projekte', u'promote', u'promoted', u'promotes', u'promoting', u'promotion', u'promotional', u'promotions', u'prompt', u'proof', u'proofreading', u'properties', u'propertiesspecialties', u'property', u'proponent', u'proponentsstakeholders', u'proposal', u'proposals', u'proposition', u'props', u'pros', u'prosecutor', u'protecting', u'protection', u'protocol', u'protocols', u'prototype', u'prototyping', u'proven', u'provide', u'provided', u'provider', u'providers', u'provides', u'providing', u'psgb', u'psychologist', u'psychology', u'ptsd', u'public', u'publication', u'publications', u'publicity', u'publicly', u'publicprivate', u'published', u'publisher', u'publishing', u'puget', u'purchase', u'purchasing', u'purdue', u'purpose', u'pursue', u'pursuing', u'pursuit', u'put', u'puzzle', u'python', u'qsic', u'quaideazam', u'qualifications', u'qualitative', u'quality', u'quantitative', u'quarterly', u'quarters', u'quest', u'questions', u'quick', u'quickbooks', u'quickly', u'race', u'radio', u'rail', u'rails', u'raised', u'raising', u'raleigh', u'raman', u'ran', u'ranch', u'randomized', u'range', u'ranging', u'ranked', u'rankings', u'rapid', u'rapidly', u'rapids', u'rapport', u'rare', u'rate', u'rates', u'rcra', u'rd', u'reach', u'read', u'reader', u'reading', u'ready', u'real', u'reality', u'realizing', u'really', u'realtor', u'realtors', u'realty', u'realworld', u'rebranding', u'receive', u'received', u'receiving', u'recent', u'recently', u'recipient', u'recognition', u'recognized', u'recognizing', u'recommendations', u'record', u'recording', u'records', u'recovery', u'recreation', u'recruiting', u'recruitment', u'red', u'redhat', u'reduce', u'reducing', u'reduction', u'reengineering', u'reference', u'refine', u'reflect', u'reflecting', u'reflective', u'reform', u'regarded', u'regarding', u'region', u'regional', u'registered', u'registration', u'regularly', u'regulations', u'regulatory', u'rehabilitation', u'related', u'relates', u'relating', u'relations', u'relationship', u'relationships', u'release', u'released', u'releases', u'relevant', u'reliability', u'reliable', u'religion', u'relocated', u'relocation', u'remain', u'remediation', u'remedy', u'remember', u'remodeling', u'remote', u'removal', u'renewable', u'replacement', u'report', u'reporter', u'reporting', u'reports', u'represent', u'representative', u'representatives', u'represented', u'representing', u'reproductive', u'reputation', u'request', u'requests', u'require', u'required', u'requirement', u'requirements', u'research', u'researcher', u'researchers', u'researching', u'reserve', u'residential', u'resolution', u'resonate', u'resource', u'resourceful', u'resourcefulness', u'resources', u'respected', u'respectful', u'response', u'responsibilities', u'responsibility', u'responsible', u'rest', u'restaurant', u'restaurants', u'restoration', u'restorative', u'restructuring', u'result', u'resulting', u'results', u'resultsdriven', u'resume', u'retail', u'retain', u'retention', u'retired', u'retirement', u'return', u'returned', u'returning', u'revenue', u'revenues', u'reverse', u'review', u'reviewer', u'reviews', u'revolves', u'rf', u'rhetoric', u'rhetorical', u'rick', u'ridiculous', u'right', u'rights', u'rigor', u'rigorous', u'rise', u'rising', u'risk', u'risks', u'river', u'rn', u'roadmaps', u'rob', u'robert', u'robotics', u'robust', u'rock', u'rodent', u'role', u'roles', u'rolling', u'rollout', u'rome', u'room', u'root', u'rory', u'ross', u'routinely', u'routing', u'royal', u'ruby', u'rule', u'run', u'running', u'rural', u'russia', u'russian', u's1', u'sabangau', u'sacramento', u'safe', u'safety', u'sale', u'sales', u'same', u'san', u'sandy', u'sanitation', u'santa', u'sas', u'satisfaction', u'save', u'savings', u'say', u'sc', u'scala', u'scalable', u'scale', u'scales', u'scenario', u'scheduling', u'scholar', u'scholars', u'scholarship', u'school', u'schools', u'science', u'sciences', u'scientific', u'scientist', u'scientists', u'scope', u'scorecard', u'scores', u'screen', u'screening', u'screenwriter', u'scripting', u'scrum', u'sdlc', u'sea', u'seamlessly', u'search', u'searches', u'searching', u'seasoned', u'seattle', u'seattlearea', u'sec', u'second', u'secondary', u'section', u'sections', u'sector', u'sectors', u'securing', u'security', u'see', u'seeing', u'seek', u'seeking', u'seeks', u'seems', u'seen', u'segmentation', u'seismic', u'seit', u'select', u'selected', u'selection', u'self', u'selfmotivated', u'selfstarter', u'sellers', u'selling', u'sem', u'semester', u'seminar', u'seminars', u'senate', u'send', u'senior', u'sense', u'sensing', u'sentencing', u'seo', u'sepa', u'september', u'series', u'sers', u'serve', u'served', u'server', u'serves', u'service', u'services', u'servicesspecialties', u'serving', u'sessions', u'set', u'sets', u'setting', u'settings', u'settlements', u'seven', u'several', u'shape', u'shapes', u'shaping', u'share', u'shared', u'shareholder', u'sharepoint', u'sharing', u'she', u'sheets', u'shell', u'shift', u'ship', u'shooter', u'shooting', u'shop', u'shopping', u'short', u'shot', u'shotcrete', u'should', u'show', u'shows', u'side', u'sigma', u'signal', u'signed', u'significant', u'significantly', u'silicon', u'silver', u'similar', u'simple', u'simplified', u'simply', u'simulation', u'simutech', u'since', u'singers', u'single', u'singlemolecule', u'singleplayer', u'site', u'sites', u'situation', u'situations', u'six', u'sixteen', u'size', u'sizes', u'skagit', u'ski', u'skiing', u'skill', u'skilled', u'skills', u'skillset', u'skin', u'slade', u'small', u'smart', u'smilie', u'snow', u'so', u'soa', u'soap', u'soccer', u'social', u'socially', u'societal', u'society', u'sociology', u'soft', u'software', u'softwarehardware', u'softwares', u'soil', u'solaris', u'sold', u'soldier', u'sole', u'solid', u'soloist', u'solution', u'solutions', u'solve', u'solvent', u'solver', u'solving', u'some', u'someone', u'something', u'sometimes', u'song', u'sony', u'soon', u'sophomore', u'sorts', u'sought', u'sound', u'soundtrack', u'source', u'sources', u'sourcing', u'south', u'southeast', u'southern', u'space', u'spaces', u'spain', u'spam', u'spanish', u'spanning', u'spans', u'speak', u'speaker', u'speakers', u'speaking', u'speaks', u'special', u'specialist', u'specialize', u'specialized', u'specializes', u'specializing', u'specialties', u'specialty', u'species', u'specific', u'specifically', u'specifications', u'spectroscopy', u'spectrum', u'speechlanguage', u'spend', u'spent', u'spill', u'spirit', u'spoken', u'sports', u'spot', u'spreadsheets', u'spring', u'sql', u'sr', u'sranantongo', u'ssl', u'st', u'stack', u'staff', u'stage', u'stages', u'stakeholder', u'stakeholders', u'standard', u'standards', u'standup', u'stanford', u'stanley', u'star', u'start', u'started', u'starting', u'starts', u'startup', u'startups', u'state', u'statelevel', u'statements', u'states', u'station', u'stations', u'statistical', u'statistics', u'status', u'stay', u'staying', u'stem', u'step', u'steps', u'steve', u'stewardship', u'still', u'store', u'stores', u'stories', u'storm', u'story', u'storytelling', u'strain', u'strains', u'strategic', u'strategically', u'strategies', u'strategist', u'strategize', u'strategy', u'strategyareashaves', u'strategyo', u'strategyto', u'stream', u'streamline', u'streamlined', u'streamlining', u'streams', u'street', u'strength', u'strengthbased', u'strengthen', u'strengthened', u'strengthening', u'strengthresults', u'strengths', u'stress', u'stressfree', u'stressful', u'strike', u'strive', u'striving', u'strong', u'strozzi', u'structure', u'structures', u'structuring', u'struggling', u'stt', u'sttram', u'stuck', u'student', u'studentcentered', u'students', u'students5', u'studentsmaster', u'studentswhat', u'studer', u'studied', u'studierte', u'studies', u'studiesfu', u'studieshis', u'studiessorbonne', u'studio', u'studios', u'studiosluftoheitgame', u'studiospartial', u'study', u'studying', u'stuff', u'style', u'styles', u'styles2', u'sub200', u'subbottom', u'subject', u'subjects', u'subjectspecialtiesstrategic', u'submissions', u'submitted', u'subordinates', u'subrogation', u'subscription', u'subseafloor', u'subsequent', u'subsequently', u'substantial', u'substitute', u'subteams', u'subterranean', u'subversion', u'succeed', u'succeeded', u'succeedhow', u'success', u'successcreation', u'successescarol', u'successesthe', u'successesthroughout', u'successful', u'successfully', u'succession', u'successmanaging', u'successmba', u'such', u'sudetendeutsche', u'sugar', u'suggest', u'suicide', u'suitable', u'suite', u'suited', u'suits', u'summa', u'summary', u'summer', u'summer6', u'summercontact', u'summers', u'sundiatafiction', u'sundry', u'sunquest', u'sunview', u'suny', u'super', u'superb', u'superconducting', u'superdrink', u'superfluous', u'superfund', u'superior', u'supervised', u'supervising', u'supervision', u'supervisioncontact', u'supervisor', u'supervisory', u'supinfo', u'suppers', u'supplementation', u'supplements', u'supplier', u'suppliers', u'supply', u'support', u'supportable', u'supported', u'supporti', u'supporting', u'supportive', u'supports', u'sure', u'surety', u'suretys', u'surface', u'surfaceenhanced', u'surfacemount', u'surfer', u'surgeon', u'surgeons', u'surgery', u'surgical', u'suriname', u'surival', u'surveillance', u'survey', u'surveybaseline', u'surveycomputerequipment', u'surveying', u'surveys', u'survivallet', u'survivors', u'susan', u'suse', u'sustain', u'sustainability', u'sustainabilityinternational', u'sustainabilityspecialties', u'sustainable', u'sustainaibility', u'sustained', u'svn', u'swanand', u'swansons', u'swat', u'swath', u'sweden', u'sweet', u'sweetest', u'swing', u'switzerland', u'sword', u'swot', u'sybase', u'sydney', u'symphony', u'symposium', u'symptoms', u'symptomsthrough', u'synchronization', u'syndicated', u'syndrome', u'synergies', u'synergistic', u'synergy', u'syngenta', u'synta', u'synthesizers', u'synthesizing', u'synthetic', u'system', u'systematic', u'systems', u'systemscompleted', u'systemscorporate', u'systemshe', u'systemsi', u'systemsin', u'systemsinterests', u'systemsoraclesapenterprise', u'systemsspecific', u'systemsxml', u'systemwere', u'ta', u'table', u'tableau', u'tablets', u'tacacs', u'tackle', u'tackling', u'tacoma', u'tactical', u'tactics', u'tagalog', u'tailored', u'taiwan', u'take', u'taken', u'takeoff', u'takes', u'taking', u'talent', u'talented', u'talents', u'talk', u'talking', u'talks', u'tamil', u'tampa', u'tangent', u'tank', u'tapc', u'target', u'targeted', u'targeting', u'targets', u'targetswere', u'tarot', u'task', u'tasked', u'tasks', u'tasksstudent', u'taste', u'tau', u'taught', u'tax', u'taxability', u'taxation', u'taxemployment', u'taxes', u'taxonomy', u'taxonomybotanical', u'taylor', u'tcl', u'tcpip', u'tdd', u'tea', u'teach', u'teacher', u'teacherseducators', u'teachertrainer', u'teaches', u'teaching', u'teachingcommunity', u'team', u'teama', u'teambuilding', u'teamfour', u'teamim', u'teaming', u'teammates', u'teammember', u'teams', u'teamsalthough', u'teamsat', u'teamsexperience', u'teamsi', u'teamspecialties', u'teamwork', u'tech', u'technical', u'technicalbusiness', u'technically', u'technician', u'technicians', u'techniques', u'technological', u'technologies', u'technologist', u'technologists', u'technology', u'technologyaipmm', u'technologycruises', u'technologyfounded', u'technologykeywords', u'technologykim', u'technologyreal', u'technologysince', u'ted', u'teens', u'tehema', u'telecom', u'telephone', u'television', u'tell', u'tellerbullshtrecent', u'telling', u'tellys', u'telnet', u'tem', u'temperaturecontrolled', u'temple', u'temporality', u'temporary', u'temptation', u'ten', u'tenacious', u'tenant', u'tend', u'tendency', u'tennessee', u'tenure', u'tenured', u'terabytes', u'term', u'terminals', u'terminology', u'terms', u'terrestrial', u'terrie', u'terrific', u'territories', u'terrorism', u'tertiary', u'tesa', u'tesollewiston', u'test', u'testament', u'tested', u'testified', u'testimony', u'testing', u'tests', u'texas', u'texasspecialtiestraining', u'texifter', u'text', u'textilesapparel', u'textures', u'than', u'thankful', u'thanks', u'that', u'thatit', u'thats', u'thayer', u'the', u'theater', u'theatre', u'their', u'them', u'themas', u'theme', u'themes', u'themi', u'themrogerrogerpimentelcomspecialties', u'themselves', u'themselvesinterview', u'then', u'theodore', u'theological', u'theorem', u'theoretical', u'theoretically', u'theories', u'theorist', u'theory', u'therapeutic', u'therapeutics', u'therapeuticsshe', u'therapies', u'therapist', u'therapy', u'therapyshe', u'there', u'thereby', u'therefore', u'therein', u'theres', u'thermal', u'thesaurus', u'these', u'thesis', u'thesisbased', u'theta', u'they', u'theyre', u'thin', u'thing', u'things', u'thingsareas', u'thingsbest', u'thingsgilmore', u'think', u'thinker', u'thinkers50', u'thinkertechnology', u'thinking', u'thinkstep', u'third', u'thirty', u'this', u'thisbroad', u'thomas', u'thompson', u'thorough', u'thoroughly', u'thoroughness', u'those', u'though', u'thought', u'thoughtful', u'thousand', u'thousands', u'threat', u'threatened', u'threats', u'three', u'threedimensional', u'threetime', u'thrive', u'thrives', u'thriving', u'thrombus', u'through', u'throughout', u'throughput', u'thunderbird', u'thus', u'tibetan', u'ticketing', u'ticor', u'tidewater', u'tiebacks', u'tier', u'tierra', u'tight', u'tilburg', u'tilebased', u'tillmanthompson', u'tilth', u'timber', u'timberland', u'timbers', u'time', u'timeconstrained', u'timeericas', u'timei', u'timelines', u'timely', u'timeresolved', u'times', u'timeshare', u'timestill', u'timetomarket', u'tip', u'tips', u'tireless', u'tissue', u'title', u'titled', u'tls', u'tmobile', u'tmz', u'tn', u'to', u'toastmasters', u'tochter', u'today', u'todays', u'toe', u'together', u'togetheri', u'tokyo', u'tolling', u'tom', u'tomorrows', u'ton', u'tonasket', u'tongue', u'tonight', u'tonyreyes30icloudcommarketer', u'too', u'took', u'tool', u'toolbox', u'tools', u'top', u'topic', u'topics', u'topography', u'topproducing', u'tops', u'tor', u'torgersen', u'toro', u'toronto', u'torontos', u'torque', u'tort', u'torts', u'total', u'touch', u'touching', u'touchpoints', u'tough', u'toulouse', u'tourism', u'toward', u'towards', u'towersbooks', u'townsend', u'towson', u'toxic', u'toxicity', u'toxicology', u'toxics', u'toys', u'toysbanking', u'tpl', u'tpls', u'tqm', u'trace', u'track', u'trackcurrently', u'tracking', u'trade', u'trademark', u'trademarks', u'trades', u'trading', u'tradition', u'traditional', u'traditionally', u'traditions', u'traffic', u'tragically', u'trail', u'trailer', u'trailers', u'trails', u'train', u'trained', u'trainer', u'trainerconsultant', u'trainers', u'training', u'traininga', u'traininghighly', u'traininglma', u'trainings', u'trainingusing', u'traits', u'trak', u'tranactions', u'transaction', u'transactions', u'transactionslaw', u'transactionsspecialtiescustomer', u'transcription', u'transcriptionist', u'transcultural', u'transduction', u'transfer', u'transferring', u'transfers', u'transform', u'transformation', u'transformational', u'transformationmodernization', u'transformationproject', u'transformative', u'transformed', u'transforming', u'transforms', u'transfusion', u'transit', u'transition', u'transitional', u'transitioned', u'transitioning', u'transitions', u'transitions3', u'translate', u'translating', u'translation', u'translator', u'transparency', u'transplant', u'transport', u'transportation', u'transportationinfrastructure', u'travel', u'travelacknowledged', u'traveled', u'traveling', u'treasurer', u'treasury', u'treat', u'treated', u'treating', u'treatment', u'treatments', u'treats', u'tree', u'treesspecialties', u'treks', u'tremendous', u'trend', u'trends', u'trete', u'trial', u'trials', u'triangle', u'tricky', u'tried', u'trildusa', u'trimble', u'trip', u'triple', u'trips', u'triservice', u'troop', u'tropical', u'trouble', u'troubled', u'troubleshooter', u'troubleshooting', u'true', u'truly', u'trust', u'trusted', u'trustee', u'trusteesspecialties', u'trustrelationship', u'trusts', u'trusty', u'truth', u'try', u'trying', u'tsa', u'tsca', u'tse', u'ttps', u'tuck', u'tumblr', u'tumor', u'tuning', u'turbine', u'turbines', u'turkey', u'turks', u'turn', u'turnarounds', u'turnbased', u'turned', u'turning', u'turnover', u'tutor', u'tutoradvocate', u'tutorials', u'tutoring', u'tutoringadvocacyesl', u'tutoringmentoring', u'tutors', u'tv', u'tvduring', u'tvvideofilm', u'twenty', u'twice', u'twitter', u'twittertweetdeck', u'two', u'tyler', u'type', u'types', u'tyra', u'ubuntu', u'uc', u'ucc', u'ucla', u'ui', u'uk', u'ultimately', u'ultrasound', u'ultrawellness', u'uncover', u'under', u'undergraduate', u'underperforming', u'underpinning', u'underserved', u'understand', u'understanding', u'undertook', u'underwriter', u'unified', u'union', u'unique', u'uniquely', u'unit', u'united', u'units', u'universities', u'university', u'universitys', u'unix', u'unsure', u'until', u'up', u'update', u'upon', u'urban', u'us', u'usa', u'usability', u'use', u'used', u'useful', u'user', u'userexperience', u'userfriendly', u'users', u'uses', u'using', u'usip', u'utilities', u'utility', u'utilization', u'utilize', u'utilizing', u'utmost', u'uw', u'ux', u'validating', u'validation', u'valley', u'valme', u'valuable', u'valuation', u'value', u'valued', u'values', u'varied', u'variety', u'various', u'vba', u'vegas', u'vehicle', u'vendor', u'vendors', u'ventures', u'venues', u'verbal', u'verification', u'versatile', u'vertical', u'very', u'veteran', u'veterans', u'via', u'viadeo', u'vibrant', u'vibrocore', u'vice', u'victim', u'victims', u'victorian', u'video', u'videos', u'view', u'violence', u'virginia', u'virtual', u'virtualization', u'virtually', u'visas', u'vision', u'visionary', u'visit', u'visiting', u'visits', u'visual', u'visualization', u'vitro', u'vmware', u'vocals', u'vogue', u'voice', u'volunteer', u'volunteering', u'von', u'voyage', u'vp', u'vulnerable', u'wa', u'wake', u'walks', u'wall', u'walls', u'want', u'wants', u'waok', u'war', u'warner', u'was', u'washington', u'washingtons', u'waste', u'watch', u'water', u'waterfall', u'way', u'waymy', u'ways', u'we', u'wealth', u'weapons', u'weather', u'weatherbank', u'web', u'webbased', u'website', u'websites', u'wedding', u'weddings', u'week', u'weekly', u'weight', u'welcome', u'well', u'wellness', u'weltweit', u'went', u'were', u'west', u'western', u'what', u'whatever', u'when', u'where', u'whether', u'which', u'while', u'white', u'whitworth', u'who', u'whoat', u'whole', u'wholeheartedly', u'wholelife', u'wholepatient', u'wholesale', u'wholesaledistribution', u'whose', u'why', u'wide', u'widely', u'wie', u'wife', u'wildlife', u'will', u'william', u'willing', u'wind', u'windows', u'wine', u'winner', u'winning', u'winter', u'winwin', u'wipo', u'wir', u'wireless', u'wisconsinmadison', u'wish', u'with', u'within', u'without', u'witness', u'women', u'womens', u'won', u'wood', u'word', u'wordpress', u'work', u'worked', u'worker', u'workers', u'workflow', u'workforce', u'working', u'workplace', u'works', u'workshop', u'workshops', u'world', u'worldclass', u'worlds', u'worldwide', u'would', u'write', u'writer', u'writereditor', u'writers', u'writing', u'writingediting', u'written', u'wrote', u'xbox', u'xml', u'xna', u'yahoo', u'ye', u'year', u'years', u'yearsspecialties', u'yes', u'yet', u'yiddish', u'yoga', u'york', u'you', u'youll', u'young', u'your', u'youre', u'youth', u'yoyos', u'zealand', u'zero', u'zhejiang', u'zone']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(X_test)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "yhat = forest.predict(test_data_features)\n",
    "\n",
    "probX = forest.predict_proba(test_data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.37  0.63]\n",
      " [ 0.42  0.58]\n",
      " [ 0.42  0.58]\n",
      " [ 0.28  0.72]\n",
      " [ 0.2   0.8 ]\n",
      " [ 0.35  0.65]\n",
      " [ 0.47  0.53]\n",
      " [ 0.52  0.48]\n",
      " [ 0.24  0.76]\n",
      " [ 0.25  0.75]\n",
      " [ 0.52  0.48]\n",
      " [ 0.35  0.65]\n",
      " [ 0.25  0.75]\n",
      " [ 0.42  0.58]\n",
      " [ 0.2   0.8 ]\n",
      " [ 0.23  0.77]\n",
      " [ 0.49  0.51]\n",
      " [ 0.39  0.61]\n",
      " [ 0.42  0.58]\n",
      " [ 0.24  0.76]\n",
      " [ 0.44  0.56]\n",
      " [ 0.48  0.52]\n",
      " [ 0.51  0.49]\n",
      " [ 0.17  0.83]\n",
      " [ 0.21  0.79]\n",
      " [ 0.29  0.71]\n",
      " [ 0.46  0.54]\n",
      " [ 0.12  0.88]\n",
      " [ 0.26  0.74]\n",
      " [ 0.51  0.49]\n",
      " [ 0.26  0.74]\n",
      " [ 0.5   0.5 ]\n",
      " [ 0.19  0.81]\n",
      " [ 0.26  0.74]\n",
      " [ 0.31  0.69]\n",
      " [ 0.27  0.73]\n",
      " [ 0.2   0.8 ]\n",
      " [ 0.2   0.8 ]\n",
      " [ 0.21  0.79]\n",
      " [ 0.24  0.76]\n",
      " [ 0.35  0.65]\n",
      " [ 0.22  0.78]\n",
      " [ 0.47  0.53]\n",
      " [ 0.18  0.82]\n",
      " [ 0.32  0.68]\n",
      " [ 0.34  0.66]\n",
      " [ 0.43  0.57]\n",
      " [ 0.59  0.41]\n",
      " [ 0.35  0.65]\n",
      " [ 0.42  0.58]\n",
      " [ 0.48  0.52]\n",
      " [ 0.27  0.73]\n",
      " [ 0.34  0.66]\n",
      " [ 0.41  0.59]\n",
      " [ 0.29  0.71]\n",
      " [ 0.13  0.87]\n",
      " [ 0.25  0.75]\n",
      " [ 0.16  0.84]\n",
      " [ 0.25  0.75]\n",
      " [ 0.21  0.79]\n",
      " [ 0.36  0.64]\n",
      " [ 0.15  0.85]\n",
      " [ 0.32  0.68]\n",
      " [ 0.42  0.58]\n",
      " [ 0.14  0.86]\n",
      " [ 0.22  0.78]\n",
      " [ 0.3   0.7 ]\n",
      " [ 0.44  0.56]\n",
      " [ 0.37  0.63]\n",
      " [ 0.24  0.76]\n",
      " [ 0.44  0.56]\n",
      " [ 0.37  0.63]\n",
      " [ 0.32  0.68]\n",
      " [ 0.38  0.62]\n",
      " [ 0.09  0.91]\n",
      " [ 0.33  0.67]\n",
      " [ 0.4   0.6 ]\n",
      " [ 0.18  0.82]\n",
      " [ 0.3   0.7 ]\n",
      " [ 0.33  0.67]\n",
      " [ 0.35  0.65]\n",
      " [ 0.33  0.67]\n",
      " [ 0.29  0.71]\n",
      " [ 0.31  0.69]\n",
      " [ 0.5   0.5 ]\n",
      " [ 0.24  0.76]\n",
      " [ 0.28  0.72]\n",
      " [ 0.52  0.48]\n",
      " [ 0.31  0.69]\n",
      " [ 0.29  0.71]\n",
      " [ 0.41  0.59]\n",
      " [ 0.21  0.79]\n",
      " [ 0.44  0.56]\n",
      " [ 0.29  0.71]\n",
      " [ 0.34  0.66]\n",
      " [ 0.34  0.66]\n",
      " [ 0.5   0.5 ]\n",
      " [ 0.31  0.69]\n",
      " [ 0.32  0.68]\n",
      " [ 0.33  0.67]\n",
      " [ 0.29  0.71]\n",
      " [ 0.25  0.75]\n",
      " [ 0.27  0.73]\n",
      " [ 0.28  0.72]\n",
      " [ 0.19  0.81]\n",
      " [ 0.26  0.74]\n",
      " [ 0.28  0.72]\n",
      " [ 0.51  0.49]\n",
      " [ 0.38  0.62]\n",
      " [ 0.12  0.88]\n",
      " [ 0.38  0.62]\n",
      " [ 0.28  0.72]\n",
      " [ 0.23  0.77]\n",
      " [ 0.31  0.69]\n",
      " [ 0.36  0.64]\n",
      " [ 0.37  0.63]\n",
      " [ 0.23  0.77]\n",
      " [ 0.37  0.63]\n",
      " [ 0.18  0.82]\n",
      " [ 0.3   0.7 ]\n",
      " [ 0.27  0.73]\n",
      " [ 0.27  0.73]\n",
      " [ 0.12  0.88]\n",
      " [ 0.52  0.48]\n",
      " [ 0.22  0.78]\n",
      " [ 0.23  0.77]\n",
      " [ 0.24  0.76]\n",
      " [ 0.23  0.77]\n",
      " [ 0.18  0.82]\n",
      " [ 0.26  0.74]\n",
      " [ 0.2   0.8 ]\n",
      " [ 0.33  0.67]\n",
      " [ 0.28  0.72]\n",
      " [ 0.37  0.63]\n",
      " [ 0.36  0.64]\n",
      " [ 0.18  0.82]]\n"
     ]
    }
   ],
   "source": [
    "zip(yhat, y_test)\n",
    "print probX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = forest.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69117647058823528"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('female', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('female', 'female'),\n",
       " ('female', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('female', 'female'),\n",
       " ('female', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('female', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('female', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('female', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('female', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'female'),\n",
       " ('male', 'male'),\n",
       " ('male', 'male')]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(yhat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.696\n",
      "Recall Score: 0.956043956044\n",
      "AUC Score: 0.5557997558\n",
      "Model Score:0.691176470588\n"
     ]
    }
   ],
   "source": [
    "print \"Precision Score: {0}\".format(precision_score(y_test, yhat))\n",
    "print \"Recall Score: {0}\".format(recall_score(y_test, yhat))\n",
    "print \"AUC Score: {0}\".format(roc_auc_score(y_test, yhat))\n",
    "print \"Model Score:{0}\".format(forest.score(test_data_features, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-dfb109408ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 477\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# stemming from floating point roundoff errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     distinct_value_indices = np.where(np.logical_not(isclose(\n\u001b[0;32m--> 319\u001b[0;31m         np.diff(y_score), 0)))[0]\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0mthreshold_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdistinct_value_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lekha/Applications/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(a, n, axis)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, yhat, pos_label=2)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
